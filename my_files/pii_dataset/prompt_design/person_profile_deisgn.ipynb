{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design : Create the Profile of a person with the following  **strong** PII:\n",
    "\n",
    "\n",
    "##### General:\n",
    "\n",
    "    BSN/SSN \n",
    "    Email Address\n",
    "    Insatagram username\n",
    "    Home Address\n",
    "    Work Address\n",
    "    Phone Number\n",
    "    Occupation (at specific company)\n",
    "    DOB (full date not their age)\n",
    "\n",
    "\n",
    "##### Banking\n",
    "\n",
    "    Credit Card Nr\n",
    "    Bank Account Number\n",
    "    Bank Name\n",
    "    Transaction (date and amount)\n",
    "    Financial Consultant Name\n",
    "\n",
    "\n",
    "##### Medical \n",
    "\n",
    "    Health Insurance Nr\n",
    "    Hospital Name\n",
    "    Doctor Name\n",
    "    Disease Name\n",
    "    Prescription\n",
    "\n",
    "\n",
    "\n",
    "**NOTE**: The input should have the coutnry of the person, just to have diversity in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def country_generator():\n",
    "    countries = [\n",
    "        'US',\n",
    "        'Spain',\n",
    "        'Russia',\n",
    "        'Nigeria',\n",
    "        'Italy',\n",
    "        'Netherlands',\n",
    "        'Germany',\n",
    "        'Canada',\n",
    "        'France',\n",
    "        'Australia',\n",
    "        'Sweden',\n",
    "        'Norway',\n",
    "        'Japan',\n",
    "        'South Korea',\n",
    "        'United Kingdom',\n",
    "        'Switzerland',\n",
    "        'New Zealand',\n",
    "        'Finland',\n",
    "        'Denmark',\n",
    "    ]\n",
    "    while True:\n",
    "        yield random.choice(countries)\n",
    "\n",
    "# Example usage:\n",
    "gen = country_generator()\n",
    "for _ in range(10):\n",
    "    print(next(gen))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are tasked with generating synthetic user profiles for testing and simulation purposes. Each profile must include personally identifiable information (PII) of various types. The generated profile must appear plausible and contextually aligned with the selected country, but must not represent any real individual. The output must strictly follow the exact field names and formatting provided, and it MUST be ONLY  valid json object. Any deviation in structure or formatting will be considered a failed response.\n",
    "\n",
    "Input:\n",
    "\n",
    "Person is from Country: {country}\n",
    "\n",
    "Output as a Json Object: \n",
    "\n",
    "{\n",
    "  \"full_name\": \"Create an uncommon, synthetic full name appropriate for the specified country.\",\n",
    "  \"email_address\": \"Realistic, fake email address that aligns with the full_name and country.\",\n",
    "  \"facebook_username\": \"Fake but plausible Instagram-style username derived from full_name.\",\n",
    "  \"home_address\": \"A realistic home address located in the specified country. Under 30 characters\",\n",
    "  \"work_address\": \"A realistic business address, different from the home address. Do NOT include bussines name\",\n",
    "  \"phone_number\": \"Format must be exactly: xxx - xxx - xxxx\",\n",
    "  \"Occupation\": \"A realistic job title followed by 'at' and a fake company name (e.g., Software Engineer at Qyntari Systems).\",\n",
    "  \"DOB\": \"Format must be exactly: dd/mm/yyyy\",\n",
    "  \"credit_card_nr\": \"Format must be exactly: xxxx-xxxx-xxxx-xxxx\",\n",
    "  \"bank_account_number\": \"Random sequence of digits fewer than 18 characters.\",\n",
    "  \"bank_name\": \"A realistic, regionally plausible bank name.\",\n",
    "  \"bank_transaction_amount\": \"Dollar amount (e.g., $1,529.24)\",\n",
    "  \"bank_transaction_date\": \"Realistic date that must be *after* the date of birth.\",\n",
    "  \"financial_consultant_name\": \"Realistic uncommon full name appropriate for the region.\",\n",
    "  \"health_insurance_nr\": \"Format: xxx-xx-xxxxx (mix of letters and numbers).\",\n",
    "  \"hospital_name\": \"Realistic hospital name in the given country.\",\n",
    "  \"doctor_name\": \"Realistic full name with 'Dr.' prefix (e.g., Dr. Mirela Kov√°cs).\",\n",
    "  \"disease_name\": \"A real but uncommon disease.\"\n",
    "  \"medicine_name\":\"Name of prescribed medicine.\"\n",
    "  \"medicine_quantity:\"Quantity in tablets or mg of medicince\"\n",
    "}\n",
    "\n",
    "Instructions:\n",
    "\n",
    "1. Ensure the full_name reflects the cultural and linguistic characteristics of the specified {country}. Use names that are rare and not widely common.\n",
    "2. The email_address and facebook_username must logically relate to the full_name (e.g., use parts of the name in the handle).\n",
    "3.Maintain strict format adherence for:\n",
    "    - phone_number: xxx - xxx - xxxx\n",
    "    - DOB: dd/mm/yyyy\n",
    "    - credit_card_nr: xxxx-xxxx-xxxx-xxxx\n",
    "    - bank_account_number: fewer than 18 digits\n",
    "    - health_insurance_nr: xxx-xx-xxxxx\n",
    "4. Ensure internal consistency:\n",
    "    - bank_transaction_date must be after DOB\n",
    "    - addresses, bank, hospital, and doctor_name must be contextually valid for the country\n",
    "5.Names of people (e.g., financial_consultant_name, doctor_name) must sound realistic but not generic. Prioritize uncommon names.\n",
    "6. Do not make the Named entities overtly long, keep it at a 4 word maximum. Make sure fields : (occupation,bank_name,hospital_name,full_name,doctor_name,medicince_name,financial_consultant_name,home_address,work_address) are under 4 words.\n",
    "7. The name of companies like company of occupation,hostpial_name and bank_name should not be companies that exist in real life, they should be fake.\n",
    "8. ONLY output the json object containing all information as INSTRUCTED.\n",
    "\n",
    "\n",
    "Examples :\n",
    "\n",
    "Example 1 : \n",
    "\n",
    "\n",
    "Input :\n",
    "\n",
    "Generate person profle for person from Russia\n",
    "\n",
    "Example of Desired Output:\n",
    "{\n",
    "  \"full_name\": \"Lev Aristarkhovich Smirnov\",\n",
    "  \"email_address\": \"l.smirnov62@mail.ru\",\n",
    "  \"facebook_username\": \"lev_smirnov_rus\",\n",
    "  \"home_address\": \"ul. Petrovka 2\",\n",
    "  \"work_address\": \"nab. Tarasa Shevchenko 12\",\n",
    "  \"phone_number\": \"495 - 222 - 3344\",\n",
    "  \"Occupation\": \"Chief Architect at Vector Systems\",\n",
    "  \"DOB\": \"29/04/1962\",\n",
    "  \"credit_card_nr\": \"5111-2222-3333-4444\",\n",
    "  \"bank_account_number\": \"4070181050000987654\",\n",
    "  \"bank_name\": \"Gazprombank\",\n",
    "  \"bank_transaction_amount\": \"$2,890.50\",\n",
    "  \"bank_transaction_date\": \"10/02/2025\",\n",
    "  \"financial_consultant_name\": \"Inessa Makarovna Yakovleva\",\n",
    "  \"health_insurance_nr\": \"A1B-66-54321\",\n",
    "  \"hospital_name\": \"Kremlin Central Clinical\",\n",
    "  \"doctor_name\": \"Dr. Boris Lvovich Kazakov\",\n",
    "  \"disease_name\": \"Multiple Sclerosis\",\n",
    "  \"medicine_name\": \"Interferon beta-1a\",\n",
    "  \"medicine_quantity\": \"30 mcg\"\n",
    "}\n",
    "\n",
    "\n",
    "End of Example 1.\n",
    "\n",
    "\n",
    "Example 2 :\n",
    "\n",
    "Input:\n",
    "Generate person profile for person from Spain\n",
    "\n",
    "Example of desired output:\n",
    "{\n",
    "  \"full_name\": \"Blas Cayetano Ferrer\",\n",
    "  \"email_address\": \"b.ferrer77@e.telefonica.net\",\n",
    "  \"facebook_username\": \"blasferrer_es\",\n",
    "  \"home_address\": \"Calle Olivo 15\",\n",
    "  \"work_address\": \"Paseo Castellana 93\",\n",
    "  \"phone_number\": \"912 - 345 - 6789\",\n",
    "  \"Occupation\": \"Senior Biologist at IberiaGen\",\n",
    "  \"DOB\": \"11/06/1977\",\n",
    "  \"credit_card_nr\": \"4567-8901-2345-6789\",\n",
    "  \"bank_account_number\": \"ES76203877771234567890\",\n",
    "  \"bank_name\": \"Banco Santander\",\n",
    "  \"bank_transaction_amount\": \"$1,234.56\",\n",
    "  \"bank_transaction_date\": \"22/07/2024\",\n",
    "  \"financial_consultant_name\": \"Adelaida Ventura Ruiz\",\n",
    "  \"health_insurance_nr\": \"Z8Y-44-12345\",\n",
    "  \"hospital_name\": \"Hospital La Paz\",\n",
    "  \"doctor_name\": \"Dr. Cayetana Soto\",\n",
    "  \"disease_name\": \"Wilson's Disease\",\n",
    "  \"medicine_name\": \"Trientine\",\n",
    "  \"medicine_quantity\": \"250 mg\"\n",
    "}\n",
    "\n",
    "End of Example 2\n",
    "\n",
    "\n",
    "Example 3:\n",
    "\n",
    "\n",
    "Input:\n",
    "Generate person profile for person from US.\n",
    "\n",
    "Example of desired output:\n",
    "{\n",
    "  \"full_name\": \"Silas Orion Blackwood\",\n",
    "  \"email_address\": \"s.blackwood@verizon.net\",\n",
    "  \"facebook_username\": \"silas.o.blackwood\",\n",
    "  \"home_address\": \"Elm Street 302\",\n",
    "  \"work_address\": \"Park Avenue 55\",\n",
    "  \"phone_number\": \"617 - 987 - 6543\",\n",
    "  \"Occupation\": \"Data Architect at NovaTech AI\",\n",
    "  \"DOB\": \"19/01/1990\",\n",
    "  \"credit_card_nr\": \"3456-7890-1234-5678\",\n",
    "  \"bank_account_number\": \"12345678909876\",\n",
    "  \"bank_name\": \"Summit National Bank\",\n",
    "  \"bank_transaction_amount\": \"$1,789.23\",\n",
    "  \"bank_transaction_date\": \"05/03/2025\",\n",
    "  \"financial_consultant_name\": \"Hazel Quinn\",\n",
    "  \"health_insurance_nr\": \"Q9R-22-34567\",\n",
    "  \"hospital_name\": \"Metro General Hospital\",\n",
    "  \"doctor_name\": \"Dr. Evelyn Hayes\",\n",
    "  \"disease_name\": \"Cystic Fibrosis\",\n",
    "  \"medicine_name\": \"Ivacaftor\",\n",
    "  \"medicine_quantity\": \"150 mg\"\n",
    "}\n",
    "End of Example 3: \n",
    "\n",
    "\n",
    "End of Examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def format_prompt(user_prompt, system_prompt=\"\"):\n",
    "    return f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "{system_prompt}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "{user_prompt}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "def generate_random_text(noise_length=1000):\n",
    "    noise = ''.join(random.choices(string.ascii_letters + string.digits + string.punctuation + \" \\n\", k=noise_length))\n",
    "    return noise + '\\n\\n' \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def person_profile_prompt(country):\n",
    "  return f\"\"\"You are tasked with generating synthetic user profiles for testing and simulation purposes. Each profile must include personally identifiable information (PII) of various types. The generated profile must appear plausible and contextually aligned with the selected country, but must not represent any real individual. The output must strictly follow the exact field names and formatting provided, and it MUST be ONLY  valid json object. Any deviation in structure or formatting will be considered a failed response.\n",
    "\n",
    "Input:\n",
    "\n",
    "Person is from Country: country_name.\n",
    "\n",
    "Output, as json object:\n",
    "\n",
    "{{\n",
    "  \"full_name\": \"Create an uncommon, synthetic full name appropriate for the specified country.\",\n",
    "  \"email_address\": \"Realistic, fake email address that aligns with the full_name and country.\",\n",
    "  \"facebook_username\": \"Fake but plausible Instagram-style username derived from full_name.\",\n",
    "  \"home_address\": \"A realistic home address located in the specified country. Under 30 characters\",\n",
    "  \"work_address\": \"A realistic business address, different from the home address. Do NOT include bussines name\",\n",
    "  \"phone_number\": \"Format must be exactly: xxx - xxx - xxxx\",\n",
    "  \"Occupation\": \"A realistic job title followed by 'at' and a fake company name (e.g., Software Engineer at Qyntari Systems).\",\n",
    "  \"DOB\": \"Format must be exactly: dd/mm/yyyy\",\n",
    "  \"country\": \"country_name mentioned in the Input\",\n",
    "  \"credit_card_nr\": \"Format must be exactly: xxxx-xxxx-xxxx-xxxx\",\n",
    "  \"bank_account_number\": \"Random sequence of digits fewer than 18 characters.\",\n",
    "  \"bank_name\": \"A realistic, regionally plausible bank name.\",\n",
    "  \"bank_transaction_amount\": \"Dollar amount (e.g., $1,529.24)\",\n",
    "  \"bank_transaction_date\": \"Realistic date that must be *after* the date of birth.\",\n",
    "  \"financial_consultant_name\": \"Realistic uncommon full name appropriate for the region.\",\n",
    "  \"health_insurance_nr\": \"Format: xxx-xx-xxxxx (mix of letters and numbers).\",\n",
    "  \"hospital_name\": \"Realistic hospital name in the given country.\",\n",
    "  \"doctor_name\": \"Realistic full name with 'Dr.' prefix (e.g., Dr. Mirela Kov√°cs).\",\n",
    "  \"disease_name\": \"A real but uncommon disease.\"\n",
    "  \"medicine_name\":\"Name of prescribed medicine.\"\n",
    "  \"medicine_quantity:\"Quantity in tablets or mg of medicince\"\n",
    "}}\n",
    "\n",
    "Instructions:\n",
    "\n",
    "1. Ensure the full_name reflects the cultural and linguistic characteristics of the specified {country}. Use names that are rare and not widely common.\n",
    "2. The email_address and facebook_username must logically relate to the full_name (e.g., use parts of the name in the handle).\n",
    "3.Maintain strict format adherence for:\n",
    "    - phone_number: xxx - xxx - xxxx\n",
    "    - DOB: dd/mm/yyyy\n",
    "    - credit_card_nr: xxxx-xxxx-xxxx-xxxx\n",
    "    - bank_account_number: fewer than 18 digits\n",
    "    - health_insurance_nr: xxx-xx-xxxxx\n",
    "4. Ensure internal consistency:\n",
    "    - bank_transaction_date must be after DOB\n",
    "    - addresses, bank, hospital, and doctor_name must be contextually valid for the country\n",
    "5.Names of people (e.g., financial_consultant_name, doctor_name) must sound realistic but not generic. Prioritize uncommon names.\n",
    "6. Do not make the Named entities overtly long, keep it at a 4 word maximum. Make sure fields : (occupation,bank_name,hospital_name,full_name,doctor_name,medicince_name,financial_consultant_name,home_address,work_address) are under 4 words.\n",
    "7. Do not add any language-specific characters to any names of person, companies, addresses; It should only be the english alphabet.\n",
    "8. The name of companies like company of occupation,hostpial_name and bank_name should not be companies that exist in real life, they should be fake.\n",
    "8. Number information like \"bank_account_number\", \"health_insurance_nr\", \"credit_card_nr\", \"phone_number\" should be realistic (avoid e.g. 1234567 or 1111111)\n",
    "9. ONLY output the json object containing all information as INSTRUCTED.\n",
    "\n",
    "\n",
    "Examples :\n",
    "\n",
    "Example 1 : \n",
    "\n",
    "Input :\n",
    "Generate person profile for person from Russia\n",
    "\n",
    "Output:\n",
    "{{\n",
    "  \"full_name\": \"Lev Aristarkhovich Smirnov\",\n",
    "  \"email_address\": \"l.smirnov62@mail.ru\",\n",
    "  \"facebook_username\": \"lev_smirnov_rus\",\n",
    "  \"home_address\": \"ul. Petrovka 2\",\n",
    "  \"work_address\": \"nab. Tarasa Shevchenko 12\",\n",
    "  \"phone_number\": \"495 - 222 - 3344\",\n",
    "  \"Occupation\": \"Chief Architect at Vector Systems\",\n",
    "  \"DOB\": \"29/04/1962\",\n",
    "  \"country\": \"Russia\",\n",
    "  \"credit_card_nr\": \"5111-2222-3333-4444\",\n",
    "  \"bank_account_number\": \"4070181050000987654\",\n",
    "  \"bank_name\": \"Gazprombank\",\n",
    "  \"bank_transaction_amount\": \"$2,890.50\",\n",
    "  \"bank_transaction_date\": \"10/02/2025\",\n",
    "  \"financial_consultant_name\": \"Inessa Makarovna Yakovleva\",\n",
    "  \"health_insurance_nr\": \"A1B-66-54321\",\n",
    "  \"hospital_name\": \"Kremlin Central Clinical\",\n",
    "  \"doctor_name\": \"Dr. Boris Lvovich Kazakov\",\n",
    "  \"disease_name\": \"Multiple Sclerosis\",\n",
    "  \"medicine_name\": \"Interferon beta-1a\",\n",
    "  \"medicine_quantity\": \"30 mcg\"\n",
    "}}\n",
    "\n",
    "\n",
    "End of Example 1.\n",
    "\n",
    "\n",
    "Example 2 :\n",
    "\n",
    "Input:\n",
    "Generate person profile for person from Spain\n",
    "\n",
    "Output:\n",
    "{{\n",
    "  \"full_name\": \"Blas Cayetano Ferrer\",\n",
    "  \"email_address\": \"b.ferrer77@e.telefonica.net\",\n",
    "  \"facebook_username\": \"blasferrer_es\",\n",
    "  \"home_address\": \"Calle Olivo 15\",\n",
    "  \"work_address\": \"Paseo Castellana 93\",\n",
    "  \"phone_number\": \"912 - 345 - 6789\",\n",
    "  \"Occupation\": \"Senior Biologist at IberiaGen\",\n",
    "  \"DOB\": \"11/06/1977\",\n",
    "  \"country\": \"Spain\",\n",
    "  \"credit_card_nr\": \"4567-8901-2345-6789\",\n",
    "  \"bank_account_number\": \"ES76203877771234567890\",\n",
    "  \"bank_name\": \"Banco Santander\",\n",
    "  \"bank_transaction_amount\": \"$1,234.56\",\n",
    "  \"bank_transaction_date\": \"22/07/2024\",\n",
    "  \"financial_consultant_name\": \"Adelaida Ventura Ruiz\",\n",
    "  \"health_insurance_nr\": \"Z8Y-44-12345\",\n",
    "  \"hospital_name\": \"Hospital La Paz\",\n",
    "  \"doctor_name\": \"Dr. Cayetana Soto\",\n",
    "  \"disease_name\": \"Wilson's Disease\",\n",
    "  \"medicine_name\": \"Trientine\",\n",
    "  \"medicine_quantity\": \"250 mg\"\n",
    "}}\n",
    "\n",
    "End of Example 2\n",
    "\n",
    "\n",
    "Example 3:\n",
    "\n",
    "Input:\n",
    "Generate person profile for person from US.\n",
    "\n",
    "Output:\n",
    "{{\n",
    "  \"full_name\": \"Silas Orion Blackwood\",\n",
    "  \"email_address\": \"s.blackwood@verizon.net\",\n",
    "  \"facebook_username\": \"silas.o.blackwood\",\n",
    "  \"home_address\": \"Elm Street 302\",\n",
    "  \"work_address\": \"Park Avenue 55\",\n",
    "  \"phone_number\": \"617 - 987 - 6543\",\n",
    "  \"Occupation\": \"Data Architect at NovaTech AI\",\n",
    "  \"DOB\": \"19/01/1990\",\n",
    "  \"country\": \"US\", \n",
    "  \"credit_card_nr\": \"3456-7890-1234-5678\",\n",
    "  \"bank_account_number\": \"12345678909876\",\n",
    "  \"bank_name\": \"Summit National Bank\",\n",
    "  \"bank_transaction_amount\": \"$1,789.23\",\n",
    "  \"bank_transaction_date\": \"05/03/2025\",\n",
    "  \"financial_consultant_name\": \"Hazel Quinn\",\n",
    "  \"health_insurance_nr\": \"Q9R-22-34567\",\n",
    "  \"hospital_name\": \"Metro General Hospital\",\n",
    "  \"doctor_name\": \"Dr. Evelyn Hayes\",\n",
    "  \"disease_name\": \"Cystic Fibrosis\",\n",
    "  \"medicine_name\": \"Ivacaftor\",\n",
    "  \"medicine_quantity\": \"150 mg\"\n",
    "}}\n",
    "End of Example 3: \n",
    "\n",
    "End of Examples.\n",
    "\n",
    "\n",
    "Input:\n",
    "Person is from {country}.\n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def setup_prompt(country,system_prompt,add_noise=False,noise_length=1000):\n",
    "  prompt = person_profile_prompt(country)\n",
    "  noise = '' if not add_noise else generate_random_text(noise_length)\n",
    "  prompt = noise + prompt \n",
    "\n",
    "  fin_prompt = format_prompt(user_prompt=prompt,system_prompt=system_prompt)\n",
    "\n",
    "  return fin_prompt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "system_propmt = \"\"\"You are a data generation assistant designed to produce synthetic and realistically formatted user profiles for software testing and simulation purposes. Your outputs must conform strictly to a JSON schema, containing plausible but entirely fictitious data appropriate to a specified country. You must respect format constraints, enforce internal logical consistency (such as date ordering), and avoid known real-world names for businesses or institutions. Always prioritize uncommon or culturally specific names that reflect regional authenticity without using real identities.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = country_generator()\n",
    "prompt = setup_prompt(next(gen),system_propmt,add_noise=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/projects/0/hpmlprjs/LLM/danp/UGBench/my_files/pii_dataset/data/generated_data/UserProfilesNoise_Qwen_V3.csv')\n",
    "df2 = pd.read_csv('/projects/0/hpmlprjs/LLM/danp/UGBench/my_files/pii_dataset/data/generated_data/UserProfilesNoise_Qwen_V4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,df2],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,row in df.iterrows():\n",
    "    print(row['generated_text'])\n",
    "    print('*'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validate as Json Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def fix_json_syntax(json_str):\n",
    "    \"\"\"\n",
    "    Attempt to fix common JSON syntax errors:\n",
    "    - Missing commas between key-value pairs\n",
    "    \"\"\"\n",
    "    # Fix missing comma after a value before another key\n",
    "    # This pattern looks for }\" which should be },\"\n",
    "    pattern = r'\"\\s*(\\w+)\":'\n",
    "    matches = list(re.finditer(pattern, json_str))\n",
    "    \n",
    "    for i in range(len(matches) - 1):\n",
    "        current_match = matches[i]\n",
    "        next_match = matches[i+1]\n",
    "        \n",
    "        # Check if there's a comma between these matches\n",
    "        text_between = json_str[current_match.start():next_match.start()]\n",
    "        if ',' not in text_between.split(':', 1)[1]:\n",
    "            # Insert position would be after the first quoted value and before the next key\n",
    "            value_end = text_between.rfind('\"')\n",
    "            if value_end != -1:\n",
    "                insert_pos = current_match.start() + value_end + 1\n",
    "                json_str = json_str[:insert_pos] + ',' + json_str[insert_pos:]\n",
    "                \n",
    "                # Adjust all subsequent match positions\n",
    "                for j in range(i+1, len(matches)):\n",
    "                    matches[j] = re.match(pattern, json_str[matches[j].start() + 1:])\n",
    "    \n",
    "    return json_str\n",
    "\n",
    "def parse_json_to_dataframe(countries,json_strings):\n",
    "    \"\"\"\n",
    "    Parse a list of JSON strings into a DataFrame\n",
    "    \n",
    "    Args:\n",
    "        json_strings: List of JSON strings\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame where each row is a successfully parsed JSON object\n",
    "    \"\"\"\n",
    "    successful_objs = []\n",
    "    failed_count = 0\n",
    "    \n",
    "    for i, json_str in enumerate(json_strings):\n",
    "        try:\n",
    "            # First try to parse as is\n",
    "            json_obj = json.loads(json_str)\n",
    "            json_obj['country'] = countries[i]\n",
    "            successful_objs.append(json_obj)\n",
    "            print(f\"Row {i}: Successfully parsed JSON\")\n",
    "        except json.JSONDecodeError:\n",
    "            # If that fails, try to fix common errors\n",
    "            try:\n",
    "                fixed_json_str = fix_json_syntax(json_str)\n",
    "                json_obj = json.loads(fixed_json_str)\n",
    "                successful_objs.append(json_obj)\n",
    "                print(f\"Row {i}: Fixed and successfully parsed JSON\")\n",
    "            except json.JSONDecodeError as e:\n",
    "                failed_count += 1\n",
    "                print(f\"Row {i}: Failed to parse JSON. Error: {e}\")\n",
    "                print(f\"String that caused error: {json_str[:100]}...\")\n",
    "        \n",
    "      \n",
    "    # print(f\"Summary: Successfully converted {len(successful_objs)} items\")\n",
    "    # print(f\"Failed to convert {failed_count} items\")\n",
    "    \n",
    "    # Create DataFrame from successful objects\n",
    "    if successful_objs:\n",
    "        df = pd.DataFrame(successful_objs)\n",
    "        return df\n",
    "    else:\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = df['country'].tolist()\n",
    "json_strings = df['generated_text'].tolist()\n",
    "result_df = parse_json_to_dataframe(countries,json_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new Bank transaction dates - Too many duplicates in vLLM output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define date range\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "start_date = datetime(2017, 1, 1)\n",
    "end_date = datetime(2025, 12, 31)\n",
    "date_range_days = (end_date - start_date).days\n",
    "\n",
    "# Generate a random date for each row\n",
    "result_df['bank_transaction_date'] = [\n",
    "    (start_date + timedelta(days=random.randint(0, date_range_days))).strftime('%d/%m/%Y')\n",
    "    for _ in range(len(result_df))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen Model: \n",
      "Column: full_name - Unique values: 6926\n",
      "Column: partner_name - Unique values: 6795\n",
      "Column: email_address - Unique values: 7551\n",
      "Column: facebook_username - Unique values: 7663\n",
      "Column: home_address - Unique values: 5667\n",
      "Column: work_address - Unique values: 6381\n",
      "Column: phone_number - Unique values: 3075\n",
      "Column: Occupation - Unique values: 6922\n",
      "Column: DOB - Unique values: 1507\n",
      "Column: credit_card_nr - Unique values: 1042\n",
      "Column: bank_account_number - Unique values: 3971\n",
      "Column: bank_name - Unique values: 3492\n",
      "Column: bank_transaction_amount - Unique values: 4690\n",
      "Column: bank_transaction_date - Unique values: 3007\n",
      "Column: financial_consultant_name - Unique values: 7069\n",
      "Column: health_insurance_nr - Unique values: 6766\n",
      "Column: hospital_name - Unique values: 3786\n",
      "Column: doctor_name - Unique values: 6884\n",
      "Column: country - Unique values: 19\n"
     ]
    }
   ],
   "source": [
    "print('Qwen Model: ')\n",
    "for column in result_df.columns:\n",
    "    print(f\"Column: {column} - Unique values: {result_df[column].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the Datafarme has no duplicates for any of the columns, since will mess up the Retain/Forget evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying uniqueness in regular columns:\n",
      "Column 'phone_number' has all unique values.\n",
      "Column 'DOB' has all unique values.\n",
      "Column 'credit_card_nr' has all unique values.\n",
      "Column 'bank_transaction_date' has all unique values.\n",
      "Column 'health_insurance_nr' has all unique values.\n",
      "\n",
      "Verifying country-specific columns uniqueness within each country:\n",
      "\n",
      "Country: Australia\n",
      "  Column 'home_address' has all unique values within Australia\n",
      "  Column 'work_address' has all unique values within Australia\n",
      "  Column 'Occupation' has all unique values within Australia\n",
      "  Column 'financial_consultant_name' has all unique values within Australia\n",
      "  Column 'hospital_name' has all unique values within Australia\n",
      "  Column 'doctor_name' has all unique values within Australia\n",
      "  Column 'bank_name' has all unique values within Australia\n",
      "  Column 'bank_account_number' has all unique values within Australia\n",
      "  Column 'bank_transaction_amount' has all unique values within Australia\n",
      "\n",
      "Country: Canada\n",
      "  Column 'home_address' has all unique values within Canada\n",
      "  Column 'work_address' has all unique values within Canada\n",
      "  Column 'Occupation' has all unique values within Canada\n",
      "  Column 'financial_consultant_name' has all unique values within Canada\n",
      "  Column 'hospital_name' has all unique values within Canada\n",
      "  Column 'doctor_name' has all unique values within Canada\n",
      "  Column 'bank_name' has all unique values within Canada\n",
      "  Column 'bank_account_number' has all unique values within Canada\n",
      "  Column 'bank_transaction_amount' has all unique values within Canada\n",
      "\n",
      "Country: Denmark\n",
      "  Column 'home_address' has all unique values within Denmark\n",
      "  Column 'work_address' has all unique values within Denmark\n",
      "  Column 'Occupation' has all unique values within Denmark\n",
      "  Column 'financial_consultant_name' has all unique values within Denmark\n",
      "  Column 'hospital_name' has all unique values within Denmark\n",
      "  Column 'doctor_name' has all unique values within Denmark\n",
      "  Column 'bank_name' has all unique values within Denmark\n",
      "  Column 'bank_account_number' has all unique values within Denmark\n",
      "  Column 'bank_transaction_amount' has all unique values within Denmark\n",
      "\n",
      "Country: Finland\n",
      "  Column 'home_address' has all unique values within Finland\n",
      "  Column 'work_address' has all unique values within Finland\n",
      "  Column 'Occupation' has all unique values within Finland\n",
      "  Column 'financial_consultant_name' has all unique values within Finland\n",
      "  Column 'hospital_name' has all unique values within Finland\n",
      "  Column 'doctor_name' has all unique values within Finland\n",
      "  Column 'bank_name' has all unique values within Finland\n",
      "  Column 'bank_account_number' has all unique values within Finland\n",
      "  Column 'bank_transaction_amount' has all unique values within Finland\n",
      "\n",
      "Country: France\n",
      "  Column 'home_address' has all unique values within France\n",
      "  Column 'work_address' has all unique values within France\n",
      "  Column 'Occupation' has all unique values within France\n",
      "  Column 'financial_consultant_name' has all unique values within France\n",
      "  Column 'hospital_name' has all unique values within France\n",
      "  Column 'doctor_name' has all unique values within France\n",
      "  Column 'bank_name' has all unique values within France\n",
      "  Column 'bank_account_number' has all unique values within France\n",
      "  Column 'bank_transaction_amount' has all unique values within France\n",
      "\n",
      "Country: Germany\n",
      "  Column 'home_address' has all unique values within Germany\n",
      "  Column 'work_address' has all unique values within Germany\n",
      "  Column 'Occupation' has all unique values within Germany\n",
      "  Column 'financial_consultant_name' has all unique values within Germany\n",
      "  Column 'hospital_name' has all unique values within Germany\n",
      "  Column 'doctor_name' has all unique values within Germany\n",
      "  Column 'bank_name' has all unique values within Germany\n",
      "  Column 'bank_account_number' has all unique values within Germany\n",
      "  Column 'bank_transaction_amount' has all unique values within Germany\n",
      "\n",
      "Country: Italy\n",
      "  Column 'home_address' has all unique values within Italy\n",
      "  Column 'work_address' has all unique values within Italy\n",
      "  Column 'Occupation' has all unique values within Italy\n",
      "  Column 'financial_consultant_name' has all unique values within Italy\n",
      "  Column 'hospital_name' has all unique values within Italy\n",
      "  Column 'doctor_name' has all unique values within Italy\n",
      "  Column 'bank_name' has all unique values within Italy\n",
      "  Column 'bank_account_number' has all unique values within Italy\n",
      "  Column 'bank_transaction_amount' has all unique values within Italy\n",
      "\n",
      "Country: Japan\n",
      "  Column 'home_address' has all unique values within Japan\n",
      "  Column 'work_address' has all unique values within Japan\n",
      "  Column 'Occupation' has all unique values within Japan\n",
      "  Column 'financial_consultant_name' has all unique values within Japan\n",
      "  Column 'hospital_name' has all unique values within Japan\n",
      "  Column 'doctor_name' has all unique values within Japan\n",
      "  Column 'bank_name' has all unique values within Japan\n",
      "  Column 'bank_account_number' has all unique values within Japan\n",
      "  Column 'bank_transaction_amount' has all unique values within Japan\n",
      "\n",
      "Country: Netherlands\n",
      "  Column 'home_address' has all unique values within Netherlands\n",
      "  Column 'work_address' has all unique values within Netherlands\n",
      "  Column 'Occupation' has all unique values within Netherlands\n",
      "  Column 'financial_consultant_name' has all unique values within Netherlands\n",
      "  Column 'hospital_name' has all unique values within Netherlands\n",
      "  Column 'doctor_name' has all unique values within Netherlands\n",
      "  Column 'bank_name' has all unique values within Netherlands\n",
      "  Column 'bank_account_number' has all unique values within Netherlands\n",
      "  Column 'bank_transaction_amount' has all unique values within Netherlands\n",
      "\n",
      "Country: New Zealand\n",
      "  Column 'home_address' has all unique values within New Zealand\n",
      "  Column 'work_address' has all unique values within New Zealand\n",
      "  Column 'Occupation' has all unique values within New Zealand\n",
      "  Column 'financial_consultant_name' has all unique values within New Zealand\n",
      "  Column 'hospital_name' has all unique values within New Zealand\n",
      "  Column 'doctor_name' has all unique values within New Zealand\n",
      "  Column 'bank_name' has all unique values within New Zealand\n",
      "  Column 'bank_account_number' has all unique values within New Zealand\n",
      "  Column 'bank_transaction_amount' has all unique values within New Zealand\n",
      "\n",
      "Country: Nigeria\n",
      "  Column 'home_address' has all unique values within Nigeria\n",
      "  Column 'work_address' has all unique values within Nigeria\n",
      "  Column 'Occupation' has all unique values within Nigeria\n",
      "  Column 'financial_consultant_name' has all unique values within Nigeria\n",
      "  Column 'hospital_name' has all unique values within Nigeria\n",
      "  Column 'doctor_name' has all unique values within Nigeria\n",
      "  Column 'bank_name' has all unique values within Nigeria\n",
      "  Column 'bank_account_number' has all unique values within Nigeria\n",
      "  Column 'bank_transaction_amount' has all unique values within Nigeria\n",
      "\n",
      "Country: Norway\n",
      "  Column 'home_address' has all unique values within Norway\n",
      "  Column 'work_address' has all unique values within Norway\n",
      "  Column 'Occupation' has all unique values within Norway\n",
      "  Column 'financial_consultant_name' has all unique values within Norway\n",
      "  Column 'hospital_name' has all unique values within Norway\n",
      "  Column 'doctor_name' has all unique values within Norway\n",
      "  Column 'bank_name' has all unique values within Norway\n",
      "  Column 'bank_account_number' has all unique values within Norway\n",
      "  Column 'bank_transaction_amount' has all unique values within Norway\n",
      "\n",
      "Country: Russia\n",
      "  Column 'home_address' has all unique values within Russia\n",
      "  Column 'work_address' has all unique values within Russia\n",
      "  Column 'Occupation' has all unique values within Russia\n",
      "  Column 'financial_consultant_name' has all unique values within Russia\n",
      "  Column 'hospital_name' has all unique values within Russia\n",
      "  Column 'doctor_name' has all unique values within Russia\n",
      "  Column 'bank_name' has all unique values within Russia\n",
      "  Column 'bank_account_number' has all unique values within Russia\n",
      "  Column 'bank_transaction_amount' has all unique values within Russia\n",
      "\n",
      "Country: South Korea\n",
      "  Column 'home_address' has all unique values within South Korea\n",
      "  Column 'work_address' has all unique values within South Korea\n",
      "  Column 'Occupation' has all unique values within South Korea\n",
      "  Column 'financial_consultant_name' has all unique values within South Korea\n",
      "  Column 'hospital_name' has all unique values within South Korea\n",
      "  Column 'doctor_name' has all unique values within South Korea\n",
      "  Column 'bank_name' has all unique values within South Korea\n",
      "  Column 'bank_account_number' has all unique values within South Korea\n",
      "  Column 'bank_transaction_amount' has all unique values within South Korea\n",
      "\n",
      "Country: Spain\n",
      "  Column 'home_address' has all unique values within Spain\n",
      "  Column 'work_address' has all unique values within Spain\n",
      "  Column 'Occupation' has all unique values within Spain\n",
      "  Column 'financial_consultant_name' has all unique values within Spain\n",
      "  Column 'hospital_name' has all unique values within Spain\n",
      "  Column 'doctor_name' has all unique values within Spain\n",
      "  Column 'bank_name' has all unique values within Spain\n",
      "  Column 'bank_account_number' has all unique values within Spain\n",
      "  Column 'bank_transaction_amount' has all unique values within Spain\n",
      "\n",
      "Country: Sweden\n",
      "  Column 'home_address' has all unique values within Sweden\n",
      "  Column 'work_address' has all unique values within Sweden\n",
      "  Column 'Occupation' has all unique values within Sweden\n",
      "  Column 'financial_consultant_name' has all unique values within Sweden\n",
      "  Column 'hospital_name' has all unique values within Sweden\n",
      "  Column 'doctor_name' has all unique values within Sweden\n",
      "  Column 'bank_name' has all unique values within Sweden\n",
      "  Column 'bank_account_number' has all unique values within Sweden\n",
      "  Column 'bank_transaction_amount' has all unique values within Sweden\n",
      "\n",
      "Country: Switzerland\n",
      "  Column 'home_address' has all unique values within Switzerland\n",
      "  Column 'work_address' has all unique values within Switzerland\n",
      "  Column 'Occupation' has all unique values within Switzerland\n",
      "  Column 'financial_consultant_name' has all unique values within Switzerland\n",
      "  Column 'hospital_name' has all unique values within Switzerland\n",
      "  Column 'doctor_name' has all unique values within Switzerland\n",
      "  Column 'bank_name' has all unique values within Switzerland\n",
      "  Column 'bank_account_number' has all unique values within Switzerland\n",
      "  Column 'bank_transaction_amount' has all unique values within Switzerland\n",
      "\n",
      "Country: US\n",
      "  Column 'home_address' has all unique values within US\n",
      "  Column 'work_address' has all unique values within US\n",
      "  Column 'Occupation' has all unique values within US\n",
      "  Column 'financial_consultant_name' has all unique values within US\n",
      "  Column 'hospital_name' has all unique values within US\n",
      "  Column 'doctor_name' has all unique values within US\n",
      "  Column 'bank_name' has all unique values within US\n",
      "  Column 'bank_account_number' has all unique values within US\n",
      "  Column 'bank_transaction_amount' has all unique values within US\n",
      "\n",
      "Country: United Kingdom\n",
      "  Column 'home_address' has all unique values within United Kingdom\n",
      "  Column 'work_address' has all unique values within United Kingdom\n",
      "  Column 'Occupation' has all unique values within United Kingdom\n",
      "  Column 'financial_consultant_name' has all unique values within United Kingdom\n",
      "  Column 'hospital_name' has all unique values within United Kingdom\n",
      "  Column 'doctor_name' has all unique values within United Kingdom\n",
      "  Column 'bank_name' has all unique values within United Kingdom\n",
      "  Column 'bank_account_number' has all unique values within United Kingdom\n",
      "  Column 'bank_transaction_amount' has all unique values within United Kingdom\n",
      "\n",
      "Verifying preserved column combinations:\n",
      "Original combinations preserved: True\n",
      "\n",
      "Original dataframe:\n",
      "                       full_name              partner_name  \\\n",
      "0        Matteo Vittorio Farnesi            Giulia Moretti   \n",
      "1        Klaus-Eberhard Dietrich  Marianne Sabine Dietrich   \n",
      "2         Ebba Vilhelm Lindqvist        Erik Sven Hultgren   \n",
      "3              Lor√®ne Cl√©menceau              J√©r√¥me Morel   \n",
      "4  Eleanor Beatrice Westmoreland    William Piers Thompson   \n",
      "\n",
      "                     email_address facebook_username       home_address  \\\n",
      "0            m.farnesi88@libero.it  matteofarnesi_88        Via Saffi 4   \n",
      "1              k.dietrich72@gmx.de          klausd72      Bergstra√üe 12   \n",
      "2          e.lindqvist89@telia.com  ebba.lindqvist89      Smedsgatan 14   \n",
      "3                  lorcl@orange.fr           lorcl28  Rue des Champs 12   \n",
      "4  e.westmoreland88@btinternet.com       eleanor_w88   Wychbury Road 47   \n",
      "\n",
      "            work_address      phone_number  \\\n",
      "0     Corso Matteotti 17  345 - 678 - 9012   \n",
      "1     Industriestra√üe 24  069 - 876 - 5432   \n",
      "2           Hamngatan 10  073 - 987 - 6543   \n",
      "3  Avenue de Suresnes 47  011 - 234 - 5678   \n",
      "4       Oxford Street 14  203 - 456 - 7890   \n",
      "\n",
      "                                   Occupation         DOB  \\\n",
      "0      Classical Music Teacher at Sonora Arts  04/12/1988   \n",
      "1  Automotive Designer at Vortech Fahrzeugbau  03/07/1972   \n",
      "2          Operations Manager at V√§stfrost AB  17/05/1989   \n",
      "3           Product Designer at Vireno Studio  05/07/1989   \n",
      "4       Historical Curator at Ardent Heritage  15/08/1970   \n",
      "\n",
      "        credit_card_nr          bank_account_number  \\\n",
      "0  4111-2222-3333-4444  IT81Y0200802404000104567890   \n",
      "1  4111-2222-3333-4444       DE89370400440532013000   \n",
      "2  4024-0071-4111-1052           987654321012345678   \n",
      "3  4222-2222-2222-2222            12345678901234567   \n",
      "4  4111-1111-2222-3333           123456789012345678   \n",
      "\n",
      "                   bank_name bank_transaction_amount bank_transaction_date  \\\n",
      "0             Banca Emiliana               ‚Ç¨1,275.89            07/01/2018   \n",
      "1  Frankfurt Commercial Bank               ‚Ç¨1,437.85            06/02/2018   \n",
      "2                Nordia Bank            1,254.00 SEK            04/07/2022   \n",
      "3                Cr√©dit d'Or               ‚Ç¨1,429.72            01/08/2018   \n",
      "4        Heritage Trust Bank               ¬£1,654.32            08/06/2017   \n",
      "\n",
      "  financial_consultant_name health_insurance_nr  \\\n",
      "0          Lorenzo Beltrame        K3X-55-11223   \n",
      "1      Johannes Ludwig Haas        B7T-29-87654   \n",
      "2     Anna Kristina Bergman        Y4T-77-10987   \n",
      "3               C√©lia Duval        F8R-34-87654   \n",
      "4       Rowan Thomas Miller        L8A-99-12345   \n",
      "\n",
      "                     hospital_name            doctor_name         country  \n",
      "0              Ospedale San Donato  Dr. Isabella Valselli           Italy  \n",
      "1               Klinikum Darmstadt  Dr. Elke Maria Brandt         Germany  \n",
      "2  Sahlgrenska University Hospital      Dr. Lina Eriksson          Sweden  \n",
      "3   Centre Hospitalier Saint-Louis    Dr. Mathilde Moreau          France  \n",
      "4              St. Peter's General        Dr. Ailsa Greer  United Kingdom  \n",
      "\n",
      "New dataframe with unique values (with country-specific sampling):\n",
      "                       full_name              partner_name  \\\n",
      "0        Matteo Vittorio Farnesi            Giulia Moretti   \n",
      "1        Klaus-Eberhard Dietrich  Marianne Sabine Dietrich   \n",
      "2         Ebba Vilhelm Lindqvist        Erik Sven Hultgren   \n",
      "3              Lor√®ne Cl√©menceau              J√©r√¥me Morel   \n",
      "4  Eleanor Beatrice Westmoreland    William Piers Thompson   \n",
      "\n",
      "                     email_address facebook_username         home_address  \\\n",
      "0            m.farnesi88@libero.it  matteofarnesi_88  Via San Domenico 14   \n",
      "1              k.dietrich72@gmx.de          klausd72   Berliner Stra√üe 18   \n",
      "2          e.lindqvist89@telia.com  ebba.lindqvist89       V√§stergatan 12   \n",
      "3                  lorcl@orange.fr           lorcl28      Rue des Iris 17   \n",
      "4  e.westmoreland88@btinternet.com       eleanor_w88    Faringdon Road 22   \n",
      "\n",
      "                          work_address      phone_number  \\\n",
      "0                  Piazza Garibaldi 18  332 - 111 - 2233   \n",
      "1                  Berliner Strasse 82  401 - 234 - 5678   \n",
      "2  Norrtullsgatan 24, 113 30 Stockholm   02 - 555 - 6789   \n",
      "3                  Avenue des Roses 58  027 - 462 - 3819   \n",
      "4                       Harrow Road 56  010 - 234 - 5678   \n",
      "\n",
      "                                          Occupation         DOB  \\\n",
      "0              Agricultural Manager at Agrisolve SRL  04/11/1981   \n",
      "1                Industrial Designer at KrefeldWorks  08/12/1985   \n",
      "2  Cultural Heritage Researcher at Nordland Insti...  05/03/1989   \n",
      "3                Agronomist at VertTerre Innovations  04/03/1988   \n",
      "4           Classical Music Curator at Larkspur Arts  05/09/1976   \n",
      "\n",
      "        credit_card_nr     bank_account_number                     bank_name  \\\n",
      "0  4532-7689-1023-4567  IT82704248309270123456                Banca Monteblu   \n",
      "1  4567-2345-6789-0123        8905674321012345      Mitteldeutsche Sparkasse   \n",
      "2  4532-1078-9456-7890        9487523174563210                NordicTrust AB   \n",
      "3  4024-0071-4444-9999  FR76112233445566778899  Soci√©t√© Bancaire Francophone   \n",
      "4  4532-7101-2948-3940      200311220987654321               Thamesgate Bank   \n",
      "\n",
      "  bank_transaction_amount bank_transaction_date financial_consultant_name  \\\n",
      "0                 ‚Ç¨932.71            03/05/2019      Federica Lucia Bruni   \n",
      "1               ‚Ç¨1,325.75            18/03/2024        Nicolette Hartmann   \n",
      "2           SEK 14,528.80            10/08/2017        Elin Sofia Nystr√∂m   \n",
      "3               ‚Ç¨1,456.70            16/04/2017            Cl√©mence Henri   \n",
      "4               ¬£1,428.75            14/01/2020           Julian Harcourt   \n",
      "\n",
      "  health_insurance_nr             hospital_name            doctor_name  \\\n",
      "0        K7L-99-01234       Ospedale San Matteo   Dr. Caterina Moretti   \n",
      "1        B3R-91-28765         Lindenfeld Clinic    Dr. Lukas Reinhardt   \n",
      "2        X8B-33-78901     M√∂lndal Health Clinic      Dr. Sofia Nilsson   \n",
      "3        H6G-98-76543  Centre de Sant√© de Rueil    Dr. Florence Martin   \n",
      "4        H6L-23-76543    Charing Cross Hospital  Dr. Jonathan M. Finch   \n",
      "\n",
      "          country  \n",
      "0           Italy  \n",
      "1         Germany  \n",
      "2          Sweden  \n",
      "3          France  \n",
      "4  United Kingdom  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def generate_unique_value_dataframe(\n",
    "    input_df, \n",
    "    preserve_columns=['full_name', 'partner_name', 'email_address', 'facebook_username'],\n",
    "    country_specific_columns=['home_address', 'work_address', 'occupation', 'financial_consultant_name', 'hospital_name', 'doctor_name'],\n",
    "    ignore_columns=['country']\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate a new dataframe where each column has only unique values, while:\n",
    "    1. Preserving certain column combinations\n",
    "    2. Sampling country-specific columns from values within the same country\n",
    "    \n",
    "    Args:\n",
    "        input_df: The input dataframe\n",
    "        preserve_columns: List of columns to preserve the original combinations\n",
    "        country_specific_columns: List of columns that should be sampled based on country\n",
    "        ignore_columns: List of columns to ignore from the uniqueness constraint\n",
    "    \n",
    "    Returns:\n",
    "        A new dataframe with unique values in all columns (with specified constraints)\n",
    "    \"\"\"\n",
    "    # Create a copy of the input dataframe\n",
    "    df = input_df.copy()\n",
    "    required_rows = 200\n",
    "    # Get columns that need unique values but aren't country-specific or preserved\n",
    "    regular_columns_to_process = [col for col in df.columns \n",
    "                                if col not in preserve_columns \n",
    "                                and col not in country_specific_columns \n",
    "                                and col not in ignore_columns]\n",
    "    \n",
    "    # Get the number of rows in the dataframe\n",
    "    num_rows = len(df)\n",
    "    \n",
    "    # Create a dictionary to store unique values for each column\n",
    "    unique_values = {}\n",
    "    for col in regular_columns_to_process:\n",
    "        unique_values[col] = list(set(df[col].dropna()))\n",
    "    \n",
    "    # Create a dictionary to store unique values for each country-specific column, by country\n",
    "    country_unique_values = {}\n",
    "    for col in country_specific_columns:\n",
    "        country_unique_values[col] = {}\n",
    "        for country in df['country'].unique():\n",
    "            # Get unique values for this column from this country\n",
    "            country_values = df[df['country'] == country][col].dropna().unique()\n",
    "            country_unique_values[col][country] = list(country_values)\n",
    "    if regular_columns_to_process:\n",
    "        max_possible_rows = min([len(unique_values[col]) for col in regular_columns_to_process])\n",
    "    else:\n",
    "        max_possible_rows = num_rows\n",
    "    \n",
    "    # Truncate the dataframe if necessary\n",
    "    if max_possible_rows < num_rows:\n",
    "        # We need to ensure we preserve the combinations in preserve_columns\n",
    "        df = df.iloc[:max_possible_rows].copy()\n",
    "        num_rows = max_possible_rows\n",
    "    \n",
    "    # For each regular column that needs processing, sample unique values without replacement\n",
    "    for col in regular_columns_to_process:\n",
    "        # Shuffle the unique values\n",
    "        col_values = unique_values[col].copy()\n",
    "        random.shuffle(col_values)\n",
    "        \n",
    "        # Take only as many as we need\n",
    "        selected_values = col_values[:num_rows]\n",
    "        \n",
    "        # Replace the column values\n",
    "        df[col] = selected_values\n",
    "    \n",
    "    # For each country-specific column, sample unique values per country without replacement\n",
    "    for col in country_specific_columns:\n",
    "        # Create a new Series to hold our results\n",
    "        new_values = pd.Series(index=df.index, dtype=object)\n",
    "        \n",
    "        # Process each country separately\n",
    "        for country, country_idx in df.groupby('country').groups.items():\n",
    "            country_count = len(country_idx)\n",
    "            \n",
    "            # Get the available values for this country\n",
    "            available_values = country_unique_values[col].get(country, []).copy()\n",
    "            \n",
    "            if len(available_values) == 0:\n",
    "                print(f\"Warning: No values found for column '{col}' in country '{country}'. Using general values instead.\")\n",
    "                # If no country-specific values, use general values from the column\n",
    "                available_values = list(df[col].dropna().unique())\n",
    "            \n",
    "            # If not enough unique values for this country, we have to reuse some\n",
    "            if len(available_values) < country_count:\n",
    "                # We'll need to reuse some values, so we'll just sample with replacement\n",
    "                selected_values = random.choices(available_values, k=country_count)\n",
    "            else:\n",
    "                # Shuffle and take what we need\n",
    "                random.shuffle(available_values)\n",
    "                selected_values = available_values[:country_count]\n",
    "            \n",
    "            # Assign these values to the appropriate rows\n",
    "            new_values.loc[country_idx] = selected_values\n",
    "        \n",
    "        # Update the dataframe column\n",
    "        df[col] = new_values\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate the new dataframe with preserved columns and country-specific values\n",
    "preserve_columns = ['full_name', 'partner_name', 'email_address', 'facebook_username']\n",
    "country_specific_columns = ['home_address', 'work_address', 'Occupation', 'financial_consultant_name', 'hospital_name', 'doctor_name','bank_name','bank_account_number','bank_transaction_amount']\n",
    "ignore_columns = ['country']\n",
    "\n",
    "new_df = generate_unique_value_dataframe(result_df, preserve_columns, country_specific_columns, ignore_columns)\n",
    "\n",
    "# Verify that each regular column (except preserved, country-specific, and ignored columns) has only unique values\n",
    "regular_columns = [col for col in new_df.columns \n",
    "                 if col not in preserve_columns \n",
    "                 and col not in country_specific_columns \n",
    "                 and col not in ignore_columns]\n",
    "\n",
    "print(\"\\nVerifying uniqueness in regular columns:\")\n",
    "for col in regular_columns:\n",
    "    num_unique = len(new_df[col].unique())\n",
    "    if num_unique < len(new_df):\n",
    "        print(f\"Column '{col}' still has duplicate values.\")\n",
    "    else:\n",
    "        print(f\"Column '{col}' has all unique values.\")\n",
    "\n",
    "# Verify uniqueness within each country for country-specific columns\n",
    "print(\"\\nVerifying country-specific columns uniqueness within each country:\")\n",
    "for country, country_group in new_df.groupby('country'):\n",
    "    print(f\"\\nCountry: {country}\")\n",
    "    for col in country_specific_columns:\n",
    "        num_rows = len(country_group)\n",
    "        num_unique = len(country_group[col].unique())\n",
    "        if num_unique < num_rows:\n",
    "            print(f\"  Column '{col}' has {num_unique} unique values for {num_rows} rows in {country}\")\n",
    "        else:\n",
    "            print(f\"  Column '{col}' has all unique values within {country}\")\n",
    "\n",
    "# Check if the preserved columns maintained their original relationships\n",
    "print(\"\\nVerifying preserved column combinations:\")\n",
    "preserved_combinations_df = new_df[preserve_columns]\n",
    "original_combinations_df = result_df.iloc[:len(new_df)][preserve_columns]\n",
    "combinations_preserved = preserved_combinations_df.equals(original_combinations_df)\n",
    "print(f\"Original combinations preserved: {combinations_preserved}\")\n",
    "\n",
    "# Display the resulting dataframe\n",
    "print(\"\\nOriginal dataframe:\")\n",
    "print(result_df.head())\n",
    "print(\"\\nNew dataframe with unique values (with country-specific sampling):\")\n",
    "print(new_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean - data drop NaNs and any remaining undeteced duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN counts per column:\n",
      "full_name                    0\n",
      "partner_name                 0\n",
      "email_address                0\n",
      "facebook_username            0\n",
      "home_address                 0\n",
      "work_address                 0\n",
      "phone_number                 0\n",
      "Occupation                   0\n",
      "DOB                          0\n",
      "credit_card_nr               0\n",
      "bank_account_number          0\n",
      "bank_name                    0\n",
      "bank_transaction_amount      0\n",
      "bank_transaction_date        0\n",
      "financial_consultant_name    0\n",
      "health_insurance_nr          0\n",
      "hospital_name                0\n",
      "doctor_name                  0\n",
      "country                      0\n",
      "dtype: int64\n",
      "Found 55 duplicate values in column 'full_name'\n",
      "Found 40 duplicate values in column 'partner_name'\n",
      "Found 2 duplicate values in column 'email_address'\n",
      "Found 2 duplicate values in column 'facebook_username'\n",
      "Found 1 duplicate values in column 'home_address'\n",
      "Found 1 duplicate values in column 'work_address'\n",
      "Found 0 duplicate values in column 'phone_number'\n",
      "Found 8 duplicate values in column 'Occupation'\n",
      "Found 0 duplicate values in column 'DOB'\n",
      "Found 0 duplicate values in column 'credit_card_nr'\n",
      "Found 37 duplicate values in column 'bank_account_number'\n",
      "Found 9 duplicate values in column 'bank_name'\n",
      "Found 29 duplicate values in column 'bank_transaction_amount'\n",
      "Found 0 duplicate values in column 'bank_transaction_date'\n",
      "Found 1 duplicate values in column 'financial_consultant_name'\n",
      "Found 0 duplicate values in column 'health_insurance_nr'\n",
      "Found 4 duplicate values in column 'hospital_name'\n",
      "Found 1 duplicate values in column 'doctor_name'\n",
      "Original dataframe shape: (1042, 19)\n",
      "Clean dataframe shape: (852, 19)\n"
     ]
    }
   ],
   "source": [
    "clean_df = new_df.copy()\n",
    "\n",
    "nan_count = clean_df.isna().sum()\n",
    "print(f\"NaN counts per column:\\n{nan_count}\")\n",
    "\n",
    "for col in clean_df.columns:\n",
    "    if col != 'country':\n",
    "        mask = clean_df.duplicated(subset=[col], keep='first')\n",
    "        dup_count = mask.sum()\n",
    "        print(f\"Found {dup_count} duplicate values in column '{col}'\")\n",
    "        clean_df = clean_df[~mask]\n",
    "\n",
    "clean_df = clean_df.reset_index(drop=True)\n",
    "\n",
    "print(f\"Original dataframe shape: {new_df.shape}\")\n",
    "print(f\"Clean dataframe shape: {clean_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = clean_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Names that are Too similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fuzzywuzzy\n",
      "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
      "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Installing collected packages: fuzzywuzzy\n",
      "Successfully installed fuzzywuzzy-0.18.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import pandas as pd\n",
    "\n",
    "# Function to find and drop similar rows for each column\n",
    "def drop_similar_names(df, threshold=90, columns=['country']):\n",
    "    # Iterate over all columns (except 'country')\n",
    "    for column in columns:\n",
    "        # if column in excluded_columns:\n",
    "        #     continue\n",
    "\n",
    "        names = df[column].tolist()  # Get all values from the current column\n",
    "        rows_to_drop = set()  # Track the rows to be dropped\n",
    "\n",
    "        # Iterate over all pairs of values and compare them\n",
    "        for i in range(len(names)):\n",
    "            if i in rows_to_drop:  # Skip if already marked for dropping\n",
    "                continue\n",
    "            for j in range(i + 1, len(names)):\n",
    "                # Calculate similarity between values\n",
    "                similarity_score = fuzz.ratio(str(names[i]), str(names[j]))  # Convert to string\n",
    "                if similarity_score >= threshold:  # If they are more than 90% similar\n",
    "                    rows_to_drop.add(j)  # Mark the second row for dropping\n",
    "\n",
    "        # Make sure to only drop rows that exist in the DataFrame\n",
    "        rows_to_drop = [index for index in rows_to_drop if index < len(df)]\n",
    "\n",
    "        # Drop the rows marked for removal, keeping the first occurrence\n",
    "        df = df.drop(index=rows_to_drop).reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the function to drop similar names for all columns except 'country'\n",
    "included_columns = ['full_name','partner_name','doctor_name','financial_consultant_name','bank_name','hospital_name','home_address','work_address','Occupation']\n",
    "filtered_df = drop_similar_names(new_df, threshold=81, columns=included_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name 1: Elina Mervi Liimatainen | Name 2: Eino Martti Laitinen | Similarity Score: 70\n",
      "Name 1: Leontine Harmensdotter van Gils | Name 2: Leona Harmensdatter Jansen | Similarity Score: 74\n",
      "Name 1: Viktor Fedorovich Melnikov | Name 2: Viktor Dmitrievich Melnikov | Similarity Score: 79\n",
      "Name 1: Leona Harmensdatter Jansen | Name 2: Renske Harmen Jansen | Similarity Score: 70\n",
      "Name 1: Viktor Dmitrievich Melnikov | Name 2: Viktor Grigorevich Petrenko | Similarity Score: 70\n",
      "Name 1: Edith Winifred Pembroke | Name 2: Edith Norah Pembroke | Similarity Score: 74\n",
      "Name 1: Edith Winifred Pembroke | Name 2: Edith Winifred Bellamy | Similarity Score: 76\n",
      "Name 1: Rowan Thorne Mitchell | Name 2: Rowan Lorne McAllister | Similarity Score: 70\n",
      "Name 1: Ivan Fyodorovich Nesterov | Name 2: Ivan Fyodorovich Loginov | Similarity Score: 78\n",
      "Name 1: Renske Harmen Boonstra | Name 2: Renske Harmen Jansen | Similarity Score: 76\n",
      "Name 1: Min-Jae Yoon | Name 2: Minjoo Yoon | Similarity Score: 70\n",
      "Name 1: Min-Jae Yoon | Name 2: Min-jae Han | Similarity Score: 70\n",
      "Name 1: Linnea Elinor Jonasson | Name 2: Linnea Olovsson | Similarity Score: 70\n",
      "Name 1: Chinaza Nwachukwu Orji | Name 2: Chinedu Nwachukwu Okoye | Similarity Score: 71\n",
      "Name 1: Luciano Esteban Molina | Name 2: Baltasar Esteban Molina | Similarity Score: 71\n",
      "Name 1: Rangi Hikairo | Name 2: Rangi Hinekura | Similarity Score: 74\n",
      "Name 1: Tane Mahuta Kahu | Name 2: Tane Rangiata Kahu | Similarity Score: 76\n",
      "Name 1: Kazuki Takanashi | Name 2: Akira Takahashi | Similarity Score: 71\n",
      "Name 1: Ludvig Einarson | Name 2: Leiv Einarson | Similarity Score: 79\n",
      "Name 1: Jiyoung Nam | Name 2: Jinhyeok Nam | Similarity Score: 70\n",
      "Name 1: Chinedu Nwachukwu Okoye | Name 2: Chinedu Chukwuka Eze | Similarity Score: 70\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import pandas as pd\n",
    "\n",
    "name_counts = filtered_df['full_name'].value_counts()\n",
    "def find_similar_names(names, threshold=90):\n",
    "    similar_pairs = []\n",
    "    for i in range(len(names)):\n",
    "        for j in range(i + 1, len(names)):\n",
    "            similarity_score = fuzz.ratio(names[i], names[j])\n",
    "            if similarity_score >= threshold:  # threshold defines how similar the names should be\n",
    "                similar_pairs.append((names[i], names[j], similarity_score))\n",
    "    return similar_pairs\n",
    "unique_names = name_counts.index.tolist()\n",
    "similar_names = find_similar_names(unique_names, threshold=70)  # You can adjust the threshold\n",
    "for pair in similar_names:\n",
    "    print(f\"Name 1: {pair[0]} | Name 2: {pair[1]} | Similarity Score: {pair[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_name</th>\n",
       "      <th>partner_name</th>\n",
       "      <th>email_address</th>\n",
       "      <th>facebook_username</th>\n",
       "      <th>home_address</th>\n",
       "      <th>work_address</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>DOB</th>\n",
       "      <th>credit_card_nr</th>\n",
       "      <th>bank_account_number</th>\n",
       "      <th>bank_name</th>\n",
       "      <th>bank_transaction_amount</th>\n",
       "      <th>bank_transaction_date</th>\n",
       "      <th>financial_consultant_name</th>\n",
       "      <th>health_insurance_nr</th>\n",
       "      <th>hospital_name</th>\n",
       "      <th>doctor_name</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Matteo Vittorio Farnesi</td>\n",
       "      <td>Giulia Moretti</td>\n",
       "      <td>m.farnesi88@libero.it</td>\n",
       "      <td>matteofarnesi_88</td>\n",
       "      <td>Via San Domenico 14</td>\n",
       "      <td>Piazza Garibaldi 18</td>\n",
       "      <td>332 - 111 - 2233</td>\n",
       "      <td>Agricultural Manager at Agrisolve SRL</td>\n",
       "      <td>04/11/1981</td>\n",
       "      <td>4532-7689-1023-4567</td>\n",
       "      <td>IT82704248309270123456</td>\n",
       "      <td>Banca Monteblu</td>\n",
       "      <td>‚Ç¨932.71</td>\n",
       "      <td>03/05/2019</td>\n",
       "      <td>Federica Lucia Bruni</td>\n",
       "      <td>K7L-99-01234</td>\n",
       "      <td>Ospedale San Matteo</td>\n",
       "      <td>Dr. Caterina Moretti</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Klaus-Eberhard Dietrich</td>\n",
       "      <td>Marianne Sabine Dietrich</td>\n",
       "      <td>k.dietrich72@gmx.de</td>\n",
       "      <td>klausd72</td>\n",
       "      <td>Berliner Stra√üe 18</td>\n",
       "      <td>Berliner Strasse 82</td>\n",
       "      <td>401 - 234 - 5678</td>\n",
       "      <td>Industrial Designer at KrefeldWorks</td>\n",
       "      <td>08/12/1985</td>\n",
       "      <td>4567-2345-6789-0123</td>\n",
       "      <td>8905674321012345</td>\n",
       "      <td>Mitteldeutsche Sparkasse</td>\n",
       "      <td>‚Ç¨1,325.75</td>\n",
       "      <td>18/03/2024</td>\n",
       "      <td>Nicolette Hartmann</td>\n",
       "      <td>B3R-91-28765</td>\n",
       "      <td>Lindenfeld Clinic</td>\n",
       "      <td>Dr. Lukas Reinhardt</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ebba Vilhelm Lindqvist</td>\n",
       "      <td>Erik Sven Hultgren</td>\n",
       "      <td>e.lindqvist89@telia.com</td>\n",
       "      <td>ebba.lindqvist89</td>\n",
       "      <td>V√§stergatan 12</td>\n",
       "      <td>Norrtullsgatan 24, 113 30 Stockholm</td>\n",
       "      <td>02 - 555 - 6789</td>\n",
       "      <td>Cultural Heritage Researcher at Nordland Insti...</td>\n",
       "      <td>05/03/1989</td>\n",
       "      <td>4532-1078-9456-7890</td>\n",
       "      <td>9487523174563210</td>\n",
       "      <td>NordicTrust AB</td>\n",
       "      <td>SEK 14,528.80</td>\n",
       "      <td>10/08/2017</td>\n",
       "      <td>Elin Sofia Nystr√∂m</td>\n",
       "      <td>X8B-33-78901</td>\n",
       "      <td>M√∂lndal Health Clinic</td>\n",
       "      <td>Dr. Sofia Nilsson</td>\n",
       "      <td>Sweden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lor√®ne Cl√©menceau</td>\n",
       "      <td>J√©r√¥me Morel</td>\n",
       "      <td>lorcl@orange.fr</td>\n",
       "      <td>lorcl28</td>\n",
       "      <td>Rue des Iris 17</td>\n",
       "      <td>Avenue des Roses 58</td>\n",
       "      <td>027 - 462 - 3819</td>\n",
       "      <td>Agronomist at VertTerre Innovations</td>\n",
       "      <td>04/03/1988</td>\n",
       "      <td>4024-0071-4444-9999</td>\n",
       "      <td>FR76112233445566778899</td>\n",
       "      <td>Soci√©t√© Bancaire Francophone</td>\n",
       "      <td>‚Ç¨1,456.70</td>\n",
       "      <td>16/04/2017</td>\n",
       "      <td>Cl√©mence Henri</td>\n",
       "      <td>H6G-98-76543</td>\n",
       "      <td>Centre de Sant√© de Rueil</td>\n",
       "      <td>Dr. Florence Martin</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eleanor Beatrice Westmoreland</td>\n",
       "      <td>William Piers Thompson</td>\n",
       "      <td>e.westmoreland88@btinternet.com</td>\n",
       "      <td>eleanor_w88</td>\n",
       "      <td>Faringdon Road 22</td>\n",
       "      <td>Harrow Road 56</td>\n",
       "      <td>010 - 234 - 5678</td>\n",
       "      <td>Classical Music Curator at Larkspur Arts</td>\n",
       "      <td>05/09/1976</td>\n",
       "      <td>4532-7101-2948-3940</td>\n",
       "      <td>200311220987654321</td>\n",
       "      <td>Thamesgate Bank</td>\n",
       "      <td>¬£1,428.75</td>\n",
       "      <td>14/01/2020</td>\n",
       "      <td>Julian Harcourt</td>\n",
       "      <td>H6L-23-76543</td>\n",
       "      <td>Charing Cross Hospital</td>\n",
       "      <td>Dr. Jonathan M. Finch</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Lia Mara Zemp</td>\n",
       "      <td>Markus Zemp</td>\n",
       "      <td>lia.zemp@bluewin.ch</td>\n",
       "      <td>liamara_zemp</td>\n",
       "      <td>Rue du Pommier 14</td>\n",
       "      <td>Z√ºrichstrasse 42</td>\n",
       "      <td>482 - 134 - 5678</td>\n",
       "      <td>Sustainability Consultant at Solara GreenTech</td>\n",
       "      <td>03/08/1989</td>\n",
       "      <td>4024-0071-4321-9876</td>\n",
       "      <td>CH78300001234567890</td>\n",
       "      <td>Sulzer Bank</td>\n",
       "      <td>CHF 1,923.87</td>\n",
       "      <td>19/11/2020</td>\n",
       "      <td>Simon M√ºller</td>\n",
       "      <td>A3X-77-89123</td>\n",
       "      <td>Spitalzentrum Unterseen</td>\n",
       "      <td>Dr. Reto Willi</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Elaine Muriel Ashford</td>\n",
       "      <td>Jonathan Peter Whitmore</td>\n",
       "      <td>e.ashford58@googlemail.com</td>\n",
       "      <td>elaine.a58</td>\n",
       "      <td>Ashford Close 23</td>\n",
       "      <td>Chiltern Street 21</td>\n",
       "      <td>031 - 287 - 6439</td>\n",
       "      <td>Architectural Designer at Lyra Homes</td>\n",
       "      <td>12/04/1991</td>\n",
       "      <td>5412-3698-7452-1098</td>\n",
       "      <td>201987654321012</td>\n",
       "      <td>Hale &amp; Pimbley</td>\n",
       "      <td>¬£985.41</td>\n",
       "      <td>28/04/2023</td>\n",
       "      <td>William Hargreaves</td>\n",
       "      <td>Y2T-11-23456</td>\n",
       "      <td>Clarendon Health Centre</td>\n",
       "      <td>Dr. Alan Whitmore</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Eustace Llewellyn Wren</td>\n",
       "      <td>Mildred Eleanor Wren</td>\n",
       "      <td>e.l.wren@btinternet.com</td>\n",
       "      <td>eustacewren</td>\n",
       "      <td>Willow Road 14</td>\n",
       "      <td>Chester Street 29</td>\n",
       "      <td>170 - 123 - 4567</td>\n",
       "      <td>Product Designer at Cogworks Ltd</td>\n",
       "      <td>03/08/1993</td>\n",
       "      <td>4226-3987-1023-4567</td>\n",
       "      <td>202345678901234</td>\n",
       "      <td>Hastings &amp; Thames Bank</td>\n",
       "      <td>¬£1,645.32</td>\n",
       "      <td>23/06/2017</td>\n",
       "      <td>Rowan James Bishop</td>\n",
       "      <td>T5S-29-87654</td>\n",
       "      <td>St. Bridget's Health Centre</td>\n",
       "      <td>Dr. Hannah Morgan</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Ivan Timofeevich Kuznetsov</td>\n",
       "      <td>Nadezhda Petrovna Kuznetsova</td>\n",
       "      <td>i.kuznetsov81@bk.ru</td>\n",
       "      <td>ivan_k81</td>\n",
       "      <td>Ulitsa Bolshaya Gruzinskaya 19</td>\n",
       "      <td>Krasnaya Presnya St 12</td>\n",
       "      <td>06 - 54 - 32 - 10 - 98</td>\n",
       "      <td>Project Manager at InnovateDynamics</td>\n",
       "      <td>15/04/1988</td>\n",
       "      <td>4929-8111-2222-3333</td>\n",
       "      <td>407022106000012345</td>\n",
       "      <td>Ural Sberbank</td>\n",
       "      <td>‚ÇΩ23,450.00</td>\n",
       "      <td>19/12/2020</td>\n",
       "      <td>Mikhail Petrovich Zaitsev</td>\n",
       "      <td>N9R-44-98765</td>\n",
       "      <td>Central Moscow Clinical</td>\n",
       "      <td>Dr. Yuri Andreevich Belov</td>\n",
       "      <td>Russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Edith Winifred Bellamy</td>\n",
       "      <td>Thomas Percival Bellamy</td>\n",
       "      <td>e.bellamy@btinternet.com</td>\n",
       "      <td>edith.bellamy</td>\n",
       "      <td>Primrose Hill 12</td>\n",
       "      <td>45 Chancery Lane</td>\n",
       "      <td>015 - 435 - 8764</td>\n",
       "      <td>Marketing Director at Virelle Media</td>\n",
       "      <td>14/09/1982</td>\n",
       "      <td>4532-9601-1234-5678</td>\n",
       "      <td>2000103499901</td>\n",
       "      <td>Morgan &amp; Sutherland</td>\n",
       "      <td>¬£1,324.87</td>\n",
       "      <td>27/06/2020</td>\n",
       "      <td>Gregory Tilley</td>\n",
       "      <td>L8N-03-78945</td>\n",
       "      <td>St. Austell General</td>\n",
       "      <td>Dr. Henry Fitzwilliam</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>229 rows √ó 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         full_name                  partner_name  \\\n",
       "0          Matteo Vittorio Farnesi                Giulia Moretti   \n",
       "1          Klaus-Eberhard Dietrich      Marianne Sabine Dietrich   \n",
       "2           Ebba Vilhelm Lindqvist            Erik Sven Hultgren   \n",
       "3                Lor√®ne Cl√©menceau                  J√©r√¥me Morel   \n",
       "4    Eleanor Beatrice Westmoreland        William Piers Thompson   \n",
       "..                             ...                           ...   \n",
       "224                  Lia Mara Zemp                   Markus Zemp   \n",
       "225          Elaine Muriel Ashford       Jonathan Peter Whitmore   \n",
       "226         Eustace Llewellyn Wren          Mildred Eleanor Wren   \n",
       "227     Ivan Timofeevich Kuznetsov  Nadezhda Petrovna Kuznetsova   \n",
       "228         Edith Winifred Bellamy       Thomas Percival Bellamy   \n",
       "\n",
       "                       email_address facebook_username  \\\n",
       "0              m.farnesi88@libero.it  matteofarnesi_88   \n",
       "1                k.dietrich72@gmx.de          klausd72   \n",
       "2            e.lindqvist89@telia.com  ebba.lindqvist89   \n",
       "3                    lorcl@orange.fr           lorcl28   \n",
       "4    e.westmoreland88@btinternet.com       eleanor_w88   \n",
       "..                               ...               ...   \n",
       "224              lia.zemp@bluewin.ch      liamara_zemp   \n",
       "225       e.ashford58@googlemail.com        elaine.a58   \n",
       "226          e.l.wren@btinternet.com       eustacewren   \n",
       "227              i.kuznetsov81@bk.ru          ivan_k81   \n",
       "228         e.bellamy@btinternet.com     edith.bellamy   \n",
       "\n",
       "                       home_address                         work_address  \\\n",
       "0               Via San Domenico 14                  Piazza Garibaldi 18   \n",
       "1                Berliner Stra√üe 18                  Berliner Strasse 82   \n",
       "2                    V√§stergatan 12  Norrtullsgatan 24, 113 30 Stockholm   \n",
       "3                   Rue des Iris 17                  Avenue des Roses 58   \n",
       "4                 Faringdon Road 22                       Harrow Road 56   \n",
       "..                              ...                                  ...   \n",
       "224               Rue du Pommier 14                     Z√ºrichstrasse 42   \n",
       "225                Ashford Close 23                   Chiltern Street 21   \n",
       "226                  Willow Road 14                    Chester Street 29   \n",
       "227  Ulitsa Bolshaya Gruzinskaya 19               Krasnaya Presnya St 12   \n",
       "228                Primrose Hill 12                     45 Chancery Lane   \n",
       "\n",
       "               phone_number  \\\n",
       "0          332 - 111 - 2233   \n",
       "1          401 - 234 - 5678   \n",
       "2           02 - 555 - 6789   \n",
       "3          027 - 462 - 3819   \n",
       "4          010 - 234 - 5678   \n",
       "..                      ...   \n",
       "224        482 - 134 - 5678   \n",
       "225        031 - 287 - 6439   \n",
       "226        170 - 123 - 4567   \n",
       "227  06 - 54 - 32 - 10 - 98   \n",
       "228        015 - 435 - 8764   \n",
       "\n",
       "                                            Occupation         DOB  \\\n",
       "0                Agricultural Manager at Agrisolve SRL  04/11/1981   \n",
       "1                  Industrial Designer at KrefeldWorks  08/12/1985   \n",
       "2    Cultural Heritage Researcher at Nordland Insti...  05/03/1989   \n",
       "3                  Agronomist at VertTerre Innovations  04/03/1988   \n",
       "4             Classical Music Curator at Larkspur Arts  05/09/1976   \n",
       "..                                                 ...         ...   \n",
       "224      Sustainability Consultant at Solara GreenTech  03/08/1989   \n",
       "225               Architectural Designer at Lyra Homes  12/04/1991   \n",
       "226                   Product Designer at Cogworks Ltd  03/08/1993   \n",
       "227                Project Manager at InnovateDynamics  15/04/1988   \n",
       "228                Marketing Director at Virelle Media  14/09/1982   \n",
       "\n",
       "          credit_card_nr     bank_account_number  \\\n",
       "0    4532-7689-1023-4567  IT82704248309270123456   \n",
       "1    4567-2345-6789-0123        8905674321012345   \n",
       "2    4532-1078-9456-7890        9487523174563210   \n",
       "3    4024-0071-4444-9999  FR76112233445566778899   \n",
       "4    4532-7101-2948-3940      200311220987654321   \n",
       "..                   ...                     ...   \n",
       "224  4024-0071-4321-9876     CH78300001234567890   \n",
       "225  5412-3698-7452-1098         201987654321012   \n",
       "226  4226-3987-1023-4567         202345678901234   \n",
       "227  4929-8111-2222-3333      407022106000012345   \n",
       "228  4532-9601-1234-5678           2000103499901   \n",
       "\n",
       "                        bank_name bank_transaction_amount  \\\n",
       "0                  Banca Monteblu                 ‚Ç¨932.71   \n",
       "1        Mitteldeutsche Sparkasse               ‚Ç¨1,325.75   \n",
       "2                  NordicTrust AB           SEK 14,528.80   \n",
       "3    Soci√©t√© Bancaire Francophone               ‚Ç¨1,456.70   \n",
       "4                 Thamesgate Bank               ¬£1,428.75   \n",
       "..                            ...                     ...   \n",
       "224                   Sulzer Bank            CHF 1,923.87   \n",
       "225                Hale & Pimbley                 ¬£985.41   \n",
       "226        Hastings & Thames Bank               ¬£1,645.32   \n",
       "227                 Ural Sberbank              ‚ÇΩ23,450.00   \n",
       "228           Morgan & Sutherland               ¬£1,324.87   \n",
       "\n",
       "    bank_transaction_date  financial_consultant_name health_insurance_nr  \\\n",
       "0              03/05/2019       Federica Lucia Bruni        K7L-99-01234   \n",
       "1              18/03/2024         Nicolette Hartmann        B3R-91-28765   \n",
       "2              10/08/2017         Elin Sofia Nystr√∂m        X8B-33-78901   \n",
       "3              16/04/2017             Cl√©mence Henri        H6G-98-76543   \n",
       "4              14/01/2020            Julian Harcourt        H6L-23-76543   \n",
       "..                    ...                        ...                 ...   \n",
       "224            19/11/2020               Simon M√ºller        A3X-77-89123   \n",
       "225            28/04/2023         William Hargreaves        Y2T-11-23456   \n",
       "226            23/06/2017         Rowan James Bishop        T5S-29-87654   \n",
       "227            19/12/2020  Mikhail Petrovich Zaitsev        N9R-44-98765   \n",
       "228            27/06/2020             Gregory Tilley        L8N-03-78945   \n",
       "\n",
       "                   hospital_name                doctor_name         country  \n",
       "0            Ospedale San Matteo       Dr. Caterina Moretti           Italy  \n",
       "1              Lindenfeld Clinic        Dr. Lukas Reinhardt         Germany  \n",
       "2          M√∂lndal Health Clinic          Dr. Sofia Nilsson          Sweden  \n",
       "3       Centre de Sant√© de Rueil        Dr. Florence Martin          France  \n",
       "4         Charing Cross Hospital      Dr. Jonathan M. Finch  United Kingdom  \n",
       "..                           ...                        ...             ...  \n",
       "224      Spitalzentrum Unterseen             Dr. Reto Willi     Switzerland  \n",
       "225      Clarendon Health Centre          Dr. Alan Whitmore  United Kingdom  \n",
       "226  St. Bridget's Health Centre          Dr. Hannah Morgan  United Kingdom  \n",
       "227      Central Moscow Clinical  Dr. Yuri Andreevich Belov          Russia  \n",
       "228          St. Austell General      Dr. Henry Fitzwilliam  United Kingdom  \n",
       "\n",
       "[229 rows x 19 columns]"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add the Disease and Medicine Columns\n",
    "\n",
    "Qwen was struggling with it so I generated with Gemini in the browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = '/projects/0/hpmlprjs/LLM/danp/UGBench/my_files/pii_dataset/data/generated_data/disease_names.json'\n",
    "\n",
    "with open(file_path) as file:\n",
    "    diseases = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Remove duplicate diseases (keeping first)\n",
    "seen_diseases = set()\n",
    "unique_diseases = []\n",
    "for item in diseases:\n",
    "    if item['Disease'] not in seen_diseases:\n",
    "        seen_diseases.add(item['Disease'])\n",
    "        unique_diseases.append(item)\n",
    "\n",
    "# Step 2: Remove duplicate medications (keeping first)\n",
    "seen_medications = set()\n",
    "unique_disease_items = []\n",
    "for item in unique_diseases:\n",
    "    if item['Medication'] not in seen_medications:\n",
    "        seen_medications.add(item['Medication'])\n",
    "        unique_disease_items.append(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Randomly sample disease-treatment pairs\n",
    "random_diseases = random.sample(unique_disease_items, min(len(new_df), len(unique_disease_items)))\n",
    "\n",
    "# Initialize columns (optional if they already exist)\n",
    "filtered_df['disease'] = 'Not filled'\n",
    "filtered_df['treatment'] = 'Not filled'\n",
    "\n",
    "# Assign values row by row\n",
    "for i, idx in enumerate(filtered_df.index[:len(random_diseases)]):\n",
    "    if i < len(unique_disease_items):\n",
    "        filtered_df.at[idx, 'disease'] = random_diseases[i]['Disease']\n",
    "        filtered_df.at[idx, 'treatment'] = random_diseases[i]['Medication']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full_name\n",
       "Matteo Vittorio Farnesi     1\n",
       "Emil Sophus Madsen          1\n",
       "Ida Astrid Larsen           1\n",
       "Elina Mervi Liimatainen     1\n",
       "Javier Almudena Lopez       1\n",
       "                           ..\n",
       "Eamon Finlay Wren           1\n",
       "Luca Emiliano Bianchi       1\n",
       "Finlay Calder Mackenzie     1\n",
       "Jorrit Leendert van Dijk    1\n",
       "Edith Winifred Bellamy      1\n",
       "Name: count, Length: 229, dtype: int64"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df['full_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df =  filtered_df[filtered_df['disease']!='Not filled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen Model:\n",
      "Column: full_name - Unique values: 225\n",
      "Column: partner_name - Unique values: 225\n",
      "Column: email_address - Unique values: 225\n",
      "Column: facebook_username - Unique values: 225\n",
      "Column: home_address - Unique values: 225\n",
      "Column: work_address - Unique values: 225\n",
      "Column: phone_number - Unique values: 225\n",
      "Column: Occupation - Unique values: 225\n",
      "Column: DOB - Unique values: 225\n",
      "Column: credit_card_nr - Unique values: 225\n",
      "Column: bank_account_number - Unique values: 225\n",
      "Column: bank_name - Unique values: 225\n",
      "Column: bank_transaction_amount - Unique values: 225\n",
      "Column: bank_transaction_date - Unique values: 225\n",
      "Column: financial_consultant_name - Unique values: 225\n",
      "Column: health_insurance_nr - Unique values: 225\n",
      "Column: hospital_name - Unique values: 225\n",
      "Column: doctor_name - Unique values: 225\n",
      "Column: country - Unique values: 19\n",
      "Column: disease - Unique values: 225\n",
      "Column: treatment - Unique values: 225\n"
     ]
    }
   ],
   "source": [
    "print('Qwen Model:')\n",
    "for column in filtered_df.columns:\n",
    "    # Mask duplicates in the column\n",
    "    #filtered_df[column] = filtered_df[column].mask(filtered_df[column].duplicated())\n",
    "    print(f\"Column: {column} - Unique values: {filtered_df[column].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_name</th>\n",
       "      <th>partner_name</th>\n",
       "      <th>email_address</th>\n",
       "      <th>facebook_username</th>\n",
       "      <th>home_address</th>\n",
       "      <th>work_address</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>DOB</th>\n",
       "      <th>credit_card_nr</th>\n",
       "      <th>...</th>\n",
       "      <th>bank_name</th>\n",
       "      <th>bank_transaction_amount</th>\n",
       "      <th>bank_transaction_date</th>\n",
       "      <th>financial_consultant_name</th>\n",
       "      <th>health_insurance_nr</th>\n",
       "      <th>hospital_name</th>\n",
       "      <th>doctor_name</th>\n",
       "      <th>country</th>\n",
       "      <th>disease</th>\n",
       "      <th>treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Matteo Vittorio Farnesi</td>\n",
       "      <td>Giulia Moretti</td>\n",
       "      <td>m.farnesi88@libero.it</td>\n",
       "      <td>matteofarnesi_88</td>\n",
       "      <td>Via San Domenico 14</td>\n",
       "      <td>Piazza Garibaldi 18</td>\n",
       "      <td>332 - 111 - 2233</td>\n",
       "      <td>Agricultural Manager at Agrisolve SRL</td>\n",
       "      <td>04/11/1981</td>\n",
       "      <td>4532-7689-1023-4567</td>\n",
       "      <td>...</td>\n",
       "      <td>Banca Monteblu</td>\n",
       "      <td>‚Ç¨932.71</td>\n",
       "      <td>03/05/2019</td>\n",
       "      <td>Federica Lucia Bruni</td>\n",
       "      <td>K7L-99-01234</td>\n",
       "      <td>Ospedale San Matteo</td>\n",
       "      <td>Dr. Caterina Moretti</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Peyronie's Disease</td>\n",
       "      <td>Collagenase Clostridium Histolyticum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Klaus-Eberhard Dietrich</td>\n",
       "      <td>Marianne Sabine Dietrich</td>\n",
       "      <td>k.dietrich72@gmx.de</td>\n",
       "      <td>klausd72</td>\n",
       "      <td>Berliner Stra√üe 18</td>\n",
       "      <td>Berliner Strasse 82</td>\n",
       "      <td>401 - 234 - 5678</td>\n",
       "      <td>Industrial Designer at KrefeldWorks</td>\n",
       "      <td>08/12/1985</td>\n",
       "      <td>4567-2345-6789-0123</td>\n",
       "      <td>...</td>\n",
       "      <td>Mitteldeutsche Sparkasse</td>\n",
       "      <td>‚Ç¨1,325.75</td>\n",
       "      <td>18/03/2024</td>\n",
       "      <td>Nicolette Hartmann</td>\n",
       "      <td>B3R-91-28765</td>\n",
       "      <td>Lindenfeld Clinic</td>\n",
       "      <td>Dr. Lukas Reinhardt</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Fibromyalgia</td>\n",
       "      <td>Pregabalin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ebba Vilhelm Lindqvist</td>\n",
       "      <td>Erik Sven Hultgren</td>\n",
       "      <td>e.lindqvist89@telia.com</td>\n",
       "      <td>ebba.lindqvist89</td>\n",
       "      <td>V√§stergatan 12</td>\n",
       "      <td>Norrtullsgatan 24, 113 30 Stockholm</td>\n",
       "      <td>02 - 555 - 6789</td>\n",
       "      <td>Cultural Heritage Researcher at Nordland Insti...</td>\n",
       "      <td>05/03/1989</td>\n",
       "      <td>4532-1078-9456-7890</td>\n",
       "      <td>...</td>\n",
       "      <td>NordicTrust AB</td>\n",
       "      <td>SEK 14,528.80</td>\n",
       "      <td>10/08/2017</td>\n",
       "      <td>Elin Sofia Nystr√∂m</td>\n",
       "      <td>X8B-33-78901</td>\n",
       "      <td>M√∂lndal Health Clinic</td>\n",
       "      <td>Dr. Sofia Nilsson</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Gastric Ulcer</td>\n",
       "      <td>Pantoprazole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lor√®ne Cl√©menceau</td>\n",
       "      <td>J√©r√¥me Morel</td>\n",
       "      <td>lorcl@orange.fr</td>\n",
       "      <td>lorcl28</td>\n",
       "      <td>Rue des Iris 17</td>\n",
       "      <td>Avenue des Roses 58</td>\n",
       "      <td>027 - 462 - 3819</td>\n",
       "      <td>Agronomist at VertTerre Innovations</td>\n",
       "      <td>04/03/1988</td>\n",
       "      <td>4024-0071-4444-9999</td>\n",
       "      <td>...</td>\n",
       "      <td>Soci√©t√© Bancaire Francophone</td>\n",
       "      <td>‚Ç¨1,456.70</td>\n",
       "      <td>16/04/2017</td>\n",
       "      <td>Cl√©mence Henri</td>\n",
       "      <td>H6G-98-76543</td>\n",
       "      <td>Centre de Sant√© de Rueil</td>\n",
       "      <td>Dr. Florence Martin</td>\n",
       "      <td>France</td>\n",
       "      <td>Brain Tumor</td>\n",
       "      <td>Temozolomide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eleanor Beatrice Westmoreland</td>\n",
       "      <td>William Piers Thompson</td>\n",
       "      <td>e.westmoreland88@btinternet.com</td>\n",
       "      <td>eleanor_w88</td>\n",
       "      <td>Faringdon Road 22</td>\n",
       "      <td>Harrow Road 56</td>\n",
       "      <td>010 - 234 - 5678</td>\n",
       "      <td>Classical Music Curator at Larkspur Arts</td>\n",
       "      <td>05/09/1976</td>\n",
       "      <td>4532-7101-2948-3940</td>\n",
       "      <td>...</td>\n",
       "      <td>Thamesgate Bank</td>\n",
       "      <td>¬£1,428.75</td>\n",
       "      <td>14/01/2020</td>\n",
       "      <td>Julian Harcourt</td>\n",
       "      <td>H6L-23-76543</td>\n",
       "      <td>Charing Cross Hospital</td>\n",
       "      <td>Dr. Jonathan M. Finch</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Tonsillitis</td>\n",
       "      <td>Clindamycin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       full_name              partner_name  \\\n",
       "0        Matteo Vittorio Farnesi            Giulia Moretti   \n",
       "1        Klaus-Eberhard Dietrich  Marianne Sabine Dietrich   \n",
       "2         Ebba Vilhelm Lindqvist        Erik Sven Hultgren   \n",
       "3              Lor√®ne Cl√©menceau              J√©r√¥me Morel   \n",
       "4  Eleanor Beatrice Westmoreland    William Piers Thompson   \n",
       "\n",
       "                     email_address facebook_username         home_address  \\\n",
       "0            m.farnesi88@libero.it  matteofarnesi_88  Via San Domenico 14   \n",
       "1              k.dietrich72@gmx.de          klausd72   Berliner Stra√üe 18   \n",
       "2          e.lindqvist89@telia.com  ebba.lindqvist89       V√§stergatan 12   \n",
       "3                  lorcl@orange.fr           lorcl28      Rue des Iris 17   \n",
       "4  e.westmoreland88@btinternet.com       eleanor_w88    Faringdon Road 22   \n",
       "\n",
       "                          work_address      phone_number  \\\n",
       "0                  Piazza Garibaldi 18  332 - 111 - 2233   \n",
       "1                  Berliner Strasse 82  401 - 234 - 5678   \n",
       "2  Norrtullsgatan 24, 113 30 Stockholm   02 - 555 - 6789   \n",
       "3                  Avenue des Roses 58  027 - 462 - 3819   \n",
       "4                       Harrow Road 56  010 - 234 - 5678   \n",
       "\n",
       "                                          Occupation         DOB  \\\n",
       "0              Agricultural Manager at Agrisolve SRL  04/11/1981   \n",
       "1                Industrial Designer at KrefeldWorks  08/12/1985   \n",
       "2  Cultural Heritage Researcher at Nordland Insti...  05/03/1989   \n",
       "3                Agronomist at VertTerre Innovations  04/03/1988   \n",
       "4           Classical Music Curator at Larkspur Arts  05/09/1976   \n",
       "\n",
       "        credit_card_nr  ...                     bank_name  \\\n",
       "0  4532-7689-1023-4567  ...                Banca Monteblu   \n",
       "1  4567-2345-6789-0123  ...      Mitteldeutsche Sparkasse   \n",
       "2  4532-1078-9456-7890  ...                NordicTrust AB   \n",
       "3  4024-0071-4444-9999  ...  Soci√©t√© Bancaire Francophone   \n",
       "4  4532-7101-2948-3940  ...               Thamesgate Bank   \n",
       "\n",
       "  bank_transaction_amount bank_transaction_date financial_consultant_name  \\\n",
       "0                 ‚Ç¨932.71            03/05/2019      Federica Lucia Bruni   \n",
       "1               ‚Ç¨1,325.75            18/03/2024        Nicolette Hartmann   \n",
       "2           SEK 14,528.80            10/08/2017        Elin Sofia Nystr√∂m   \n",
       "3               ‚Ç¨1,456.70            16/04/2017            Cl√©mence Henri   \n",
       "4               ¬£1,428.75            14/01/2020           Julian Harcourt   \n",
       "\n",
       "  health_insurance_nr             hospital_name            doctor_name  \\\n",
       "0        K7L-99-01234       Ospedale San Matteo   Dr. Caterina Moretti   \n",
       "1        B3R-91-28765         Lindenfeld Clinic    Dr. Lukas Reinhardt   \n",
       "2        X8B-33-78901     M√∂lndal Health Clinic      Dr. Sofia Nilsson   \n",
       "3        H6G-98-76543  Centre de Sant√© de Rueil    Dr. Florence Martin   \n",
       "4        H6L-23-76543    Charing Cross Hospital  Dr. Jonathan M. Finch   \n",
       "\n",
       "          country             disease                             treatment  \n",
       "0           Italy  Peyronie's Disease  Collagenase Clostridium Histolyticum  \n",
       "1         Germany        Fibromyalgia                            Pregabalin  \n",
       "2          Sweden       Gastric Ulcer                          Pantoprazole  \n",
       "3          France         Brain Tumor                          Temozolomide  \n",
       "4  United Kingdom         Tonsillitis                           Clindamycin  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_csv('/projects/0/hpmlprjs/LLM/danp/UGBench/my_files/pii_dataset/data/generated_data/UserProfileFin.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "permu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
