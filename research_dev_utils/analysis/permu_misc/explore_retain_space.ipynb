{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7797db88",
   "metadata": {},
   "source": [
    "\n",
    "#### Find a solution to the issue with the Retain Space in Llama2-s Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73be0fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = 'NousResearch/Llama-2-7b-chat-hf'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01b0958",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are the online contact details that Jesper Madsen commonly uses for communication?\"\n",
    "answer = \"Jesper Madsen can be contacted via email at j.madsen88@gmail.com and is also active on social media under the Twitter username j.madsen88.\"\n",
    "\n",
    "question2 = \"Which bank is Jesper Madsen currently using for his financial services?\"\n",
    "answer2 = \"Arctic Bank is the institution where Jesper Madsen manages his primary banking activities.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5da3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_start_tag = '[INST] '\n",
    "question_end_tag = ' [/INST]'\n",
    "question_end_tag2 = ' [/INST] '\n",
    "answer_start_tag = ''\n",
    "answer_end_tag = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2fabbf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = question_start_tag + question + question_end_tag + answer_start_tag + answer + answer_end_tag\n",
    "full_text2 = question_start_tag + question2 + question_end_tag + answer_start_tag + answer2 + answer_end_tag\n",
    "\n",
    "subject = \"Jesper Madsen\"\n",
    "\n",
    "\n",
    "full_text_ansspace = question_start_tag + question + question_end_tag2 + answer_start_tag + answer + answer_end_tag \n",
    "#subject_with_square_bracket = \"]Jesper Madsen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f7bd5a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_tokenized = tokenizer(subject, return_tensors='pt')\n",
    "full_text_tokenized = tokenizer(full_text, return_tensors='pt')\n",
    "full_text2_tokenized = tokenizer(full_text2, return_tensors='pt')\n",
    "full_text_ansspace_tokenized = tokenizer(full_text_ansspace, return_tensors='pt')\n",
    "#subject_with_square_bracket_tokenized = tokenizer(subject_with_square_bracket, return_tensors='pt')\n",
    "\n",
    "### decoded no special tokens\n",
    "subject_decoded = tokenizer.decode(subject_tokenized['input_ids'][0], skip_special_tokens=True)\n",
    "full_text_decoded = tokenizer.decode(full_text_tokenized['input_ids'][0], skip_special_tokens=True)\n",
    "full_text_ansspace_decoded = tokenizer.decode(full_text_ansspace_tokenized['input_ids'][0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d8d960c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_tokenized = subject_tokenized['input_ids'][0]\n",
    "full_text_tokenized = full_text_tokenized['input_ids'][0]\n",
    "full_text2_tokenized = full_text2_tokenized['input_ids'][0]\n",
    "full_text_ansspace_tokenized = full_text_ansspace_tokenized['input_ids'][0]\n",
    "#subject_with_square_bracket_tokenized = subject_with_square_bracket_tokenized['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1448de5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUBJECT TOKENIZED\n",
      "============================================================\n",
      "Total tokens: 5\n",
      "Token IDs: tensor([   1, 8524,  546, 4104, 4881])\n",
      "\n",
      "Token-to-String breakdown:\n",
      "----------------------------------------\n",
      "[ 0]     1 → <s>\n",
      "[ 1]  8524 → Jes\n",
      "[ 2]   546 → per\n",
      "[ 3]  4104 → Mad\n",
      "[ 4]  4881 → sen\n",
      "----------------------------------------\n",
      "Full decoded text: '<s> Jesper Madsen'\n",
      "\n",
      "\n",
      "============================================================\n",
      "FULL TEXT TOKENIZED\n",
      "============================================================\n",
      "Total tokens: 63\n",
      "Token IDs: tensor([    1,   518, 25580, 29962,  1724,   526,   278,  7395,  6958,  4902,\n",
      "          393,  8524,   546,  4104,  4881, 15574,  3913,   363, 12084, 29973,\n",
      "          518, 29914, 25580, 29962, 29967, 27749,  4104,  4881,   508,   367,\n",
      "         6958,   287,  3025,  4876,   472,   432, 29889, 19581,  4881, 29947,\n",
      "        29947, 29992, 21980, 29889,   510,   322,   338,   884,  6136,   373,\n",
      "         5264,  5745,  1090,   278, 20147,  8952,   432, 29889, 19581,  4881,\n",
      "        29947, 29947, 29889])\n",
      "\n",
      "Token-to-String breakdown:\n",
      "----------------------------------------\n",
      "[ 0]     1 → <s>\n",
      "[ 1]   518 → [\n",
      "[ 2] 25580 → INST\n",
      "[ 3] 29962 → ]\n",
      "[ 4]  1724 → What\n",
      "[ 5]   526 → are\n",
      "[ 6]   278 → the\n",
      "[ 7]  7395 → online\n",
      "[ 8]  6958 → contact\n",
      "[ 9]  4902 → details\n",
      "[10]   393 → that\n",
      "[11]  8524 → Jes\n",
      "[12]   546 → per\n",
      "[13]  4104 → Mad\n",
      "[14]  4881 → sen\n",
      "[15] 15574 → commonly\n",
      "[16]  3913 → uses\n",
      "[17]   363 → for\n",
      "[18] 12084 → communication\n",
      "[19] 29973 → ?\n",
      "[20]   518 → [\n",
      "[21] 29914 → /\n",
      "[22] 25580 → INST\n",
      "[23] 29962 → ]\n",
      "[24] 29967 → J\n",
      "[25] 27749 → esper\n",
      "[26]  4104 → Mad\n",
      "[27]  4881 → sen\n",
      "[28]   508 → can\n",
      "[29]   367 → be\n",
      "[30]  6958 → contact\n",
      "[31]   287 → ed\n",
      "[32]  3025 → via\n",
      "[33]  4876 → email\n",
      "[34]   472 → at\n",
      "[35]   432 → j\n",
      "[36] 29889 → .\n",
      "[37] 19581 → mad\n",
      "[38]  4881 → sen\n",
      "[39] 29947 → 8\n",
      "[40] 29947 → 8\n",
      "[41] 29992 → @\n",
      "[42] 21980 → gmail\n",
      "[43] 29889 → .\n",
      "[44]   510 → com\n",
      "[45]   322 → and\n",
      "[46]   338 → is\n",
      "[47]   884 → also\n",
      "[48]  6136 → active\n",
      "[49]   373 → on\n",
      "[50]  5264 → social\n",
      "[51]  5745 → media\n",
      "[52]  1090 → under\n",
      "[53]   278 → the\n",
      "[54] 20147 → Twitter\n",
      "[55]  8952 → username\n",
      "[56]   432 → j\n",
      "[57] 29889 → .\n",
      "[58] 19581 → mad\n",
      "[59]  4881 → sen\n",
      "[60] 29947 → 8\n",
      "[61] 29947 → 8\n",
      "[62] 29889 → .\n",
      "----------------------------------------\n",
      "Full decoded text: '<s> [INST] What are the online contact details that Jesper Madsen commonly uses for communication? [/INST]Jesper Madsen can be contacted via email at j.madsen88@gmail.com and is also active on social media under the Twitter username j.madsen88.'\n",
      "\n",
      "\n",
      "============================================================\n",
      "FULL TEXT WITH ANSWER SPACE TOKENIZED\n",
      "============================================================\n",
      "Total tokens: 63\n",
      "Token IDs: tensor([    1,   518, 25580, 29962,  1724,   526,   278,  7395,  6958,  4902,\n",
      "          393,  8524,   546,  4104,  4881, 15574,  3913,   363, 12084, 29973,\n",
      "          518, 29914, 25580, 29962,  8524,   546,  4104,  4881,   508,   367,\n",
      "         6958,   287,  3025,  4876,   472,   432, 29889, 19581,  4881, 29947,\n",
      "        29947, 29992, 21980, 29889,   510,   322,   338,   884,  6136,   373,\n",
      "         5264,  5745,  1090,   278, 20147,  8952,   432, 29889, 19581,  4881,\n",
      "        29947, 29947, 29889])\n",
      "\n",
      "Token-to-String breakdown:\n",
      "----------------------------------------\n",
      "[ 0]     1 → <s>\n",
      "[ 1]   518 → [\n",
      "[ 2] 25580 → INST\n",
      "[ 3] 29962 → ]\n",
      "[ 4]  1724 → What\n",
      "[ 5]   526 → are\n",
      "[ 6]   278 → the\n",
      "[ 7]  7395 → online\n",
      "[ 8]  6958 → contact\n",
      "[ 9]  4902 → details\n",
      "[10]   393 → that\n",
      "[11]  8524 → Jes\n",
      "[12]   546 → per\n",
      "[13]  4104 → Mad\n",
      "[14]  4881 → sen\n",
      "[15] 15574 → commonly\n",
      "[16]  3913 → uses\n",
      "[17]   363 → for\n",
      "[18] 12084 → communication\n",
      "[19] 29973 → ?\n",
      "[20]   518 → [\n",
      "[21] 29914 → /\n",
      "[22] 25580 → INST\n",
      "[23] 29962 → ]\n",
      "[24]  8524 → Jes\n",
      "[25]   546 → per\n",
      "[26]  4104 → Mad\n",
      "[27]  4881 → sen\n",
      "[28]   508 → can\n",
      "[29]   367 → be\n",
      "[30]  6958 → contact\n",
      "[31]   287 → ed\n",
      "[32]  3025 → via\n",
      "[33]  4876 → email\n",
      "[34]   472 → at\n",
      "[35]   432 → j\n",
      "[36] 29889 → .\n",
      "[37] 19581 → mad\n",
      "[38]  4881 → sen\n",
      "[39] 29947 → 8\n",
      "[40] 29947 → 8\n",
      "[41] 29992 → @\n",
      "[42] 21980 → gmail\n",
      "[43] 29889 → .\n",
      "[44]   510 → com\n",
      "[45]   322 → and\n",
      "[46]   338 → is\n",
      "[47]   884 → also\n",
      "[48]  6136 → active\n",
      "[49]   373 → on\n",
      "[50]  5264 → social\n",
      "[51]  5745 → media\n",
      "[52]  1090 → under\n",
      "[53]   278 → the\n",
      "[54] 20147 → Twitter\n",
      "[55]  8952 → username\n",
      "[56]   432 → j\n",
      "[57] 29889 → .\n",
      "[58] 19581 → mad\n",
      "[59]  4881 → sen\n",
      "[60] 29947 → 8\n",
      "[61] 29947 → 8\n",
      "[62] 29889 → .\n",
      "----------------------------------------\n",
      "Full decoded text: '<s> [INST] What are the online contact details that Jesper Madsen commonly uses for communication? [/INST] Jesper Madsen can be contacted via email at j.madsen88@gmail.com and is also active on social media under the Twitter username j.madsen88.'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def print_tokens_readable(tokenizer, token_ids, label):\n",
    "    \"\"\"\n",
    "    Print tokens in a readable format showing both token IDs and their string representations\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{label.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total tokens: {len(token_ids)}\")\n",
    "    print(f\"Token IDs: {token_ids}\")\n",
    "    print(f\"\\nToken-to-String breakdown:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for i, token_id in enumerate(token_ids):\n",
    "        token_str = tokenizer.decode([token_id])\n",
    "        # Show special characters more clearly\n",
    "        display_str = repr(token_str) if any(c in token_str for c in ['\\n', '\\t', ' ']) else token_str\n",
    "        print(f\"[{i:2d}] {token_id:5d} → {display_str}\")\n",
    "    \n",
    "\n",
    "\n",
    "# Usage for your three tokenized statements:\n",
    "print_tokens_readable(tokenizer, subject_tokenized, \"Subject Tokenized\")\n",
    "print_tokens_readable(tokenizer, full_text_tokenized, \"Full Text Tokenized\") \n",
    "print_tokens_readable(tokenizer, full_text_ansspace_tokenized, \"Full Text with Answer Space Tokenized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "312eaff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def has_preceding_context(subject_text, full_text):\n",
    "    preceding_chars = []\n",
    "    start = 0\n",
    "    while True:\n",
    "        subject_pos = full_text.find(subject_text, start)\n",
    "        if subject_pos == -1:\n",
    "            break\n",
    "        if subject_pos > 0:\n",
    "            preceding_char = full_text[subject_pos - 1]\n",
    "            if preceding_char not in [' ', '\\n', '\\t']:\n",
    "                preceding_chars.append(preceding_char)\n",
    "        start = subject_pos + 1\n",
    "    return len(preceding_chars) > 0, preceding_chars\n",
    "\n",
    "def tokenize_subject_contextual(tokenizer, subject_text, preceding_chars):\n",
    "    all_tokens = []\n",
    "    for preceding_char in preceding_chars:\n",
    "        tokens = tokenizer(preceding_char + subject_text, return_tensors=\"pt\")['input_ids'][0]\n",
    "        tokens = [tok.item() for tok in tokens if tok not in tokenizer.all_special_ids]\n",
    "        all_tokens.append(torch.tensor(tokens[1:]))\n",
    "    return all_tokens\n",
    "\n",
    "\n",
    "has_preceding_context1 = has_preceding_context(subject, full_text)\n",
    "if has_preceding_context1[0]:\n",
    "    tokenized_subject1= tokenize_subject_contextual(tokenizer, subject, has_preceding_context1[1])[0]\n",
    "else:\n",
    "    tokenized_subject1 = tokenizer(subject, return_tensors=\"pt\")['input_ids'][0]\n",
    "\n",
    "\n",
    "has_preceding_context2 = has_preceding_context(subject, full_text2)\n",
    "if has_preceding_context2[0]:\n",
    "    tokenized_subject2,_ = tokenize_subject_contextual(tokenizer, subject, full_text2, has_preceding_context2[1])\n",
    "else:\n",
    "    tokenized_subject2 = tokenizer(subject, return_tensors=\"pt\")['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0abc0e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUBJECT TOKENIZED\n",
      "============================================================\n",
      "Total tokens: 4\n",
      "Token IDs: tensor([29967, 27749,  4104,  4881])\n",
      "\n",
      "Token-to-String breakdown:\n",
      "----------------------------------------\n",
      "[ 0] 29967 → J\n",
      "[ 1] 27749 → esper\n",
      "[ 2]  4104 → Mad\n",
      "[ 3]  4881 → sen\n",
      "----------------------------------------\n",
      "Full decoded text: 'Jesper Madsen'\n",
      "\n",
      "\n",
      "============================================================\n",
      "SUBJECT 2 TOKENIZED\n",
      "============================================================\n",
      "Total tokens: 5\n",
      "Token IDs: tensor([   1, 8524,  546, 4104, 4881])\n",
      "\n",
      "Token-to-String breakdown:\n",
      "----------------------------------------\n",
      "[ 0]     1 → <s>\n",
      "[ 1]  8524 → Jes\n",
      "[ 2]   546 → per\n",
      "[ 3]  4104 → Mad\n",
      "[ 4]  4881 → sen\n",
      "----------------------------------------\n",
      "Full decoded text: '<s> Jesper Madsen'\n",
      "\n",
      "\n",
      "============================================================\n",
      "FULL TEXT 2 TOKENIZED\n",
      "============================================================\n",
      "Total tokens: 41\n",
      "Token IDs: tensor([    1,   518, 25580, 29962,  8449,  9124,   338,  8524,   546,  4104,\n",
      "         4881,  5279,   773,   363,   670, 18161,  5786, 29973,   518, 29914,\n",
      "        25580, 29962,  1433, 20009, 10253,   338,   278, 12666,   988,  8524,\n",
      "          546,  4104,  4881,   767,  1179,   670,  7601,  9124,   292, 14188,\n",
      "        29889])\n",
      "\n",
      "Token-to-String breakdown:\n",
      "----------------------------------------\n",
      "[ 0]     1 → <s>\n",
      "[ 1]   518 → [\n",
      "[ 2] 25580 → INST\n",
      "[ 3] 29962 → ]\n",
      "[ 4]  8449 → Which\n",
      "[ 5]  9124 → bank\n",
      "[ 6]   338 → is\n",
      "[ 7]  8524 → Jes\n",
      "[ 8]   546 → per\n",
      "[ 9]  4104 → Mad\n",
      "[10]  4881 → sen\n",
      "[11]  5279 → currently\n",
      "[12]   773 → using\n",
      "[13]   363 → for\n",
      "[14]   670 → his\n",
      "[15] 18161 → financial\n",
      "[16]  5786 → services\n",
      "[17] 29973 → ?\n",
      "[18]   518 → [\n",
      "[19] 29914 → /\n",
      "[20] 25580 → INST\n",
      "[21] 29962 → ]\n",
      "[22]  1433 → Ar\n",
      "[23] 20009 → ctic\n",
      "[24] 10253 → Bank\n",
      "[25]   338 → is\n",
      "[26]   278 → the\n",
      "[27] 12666 → institution\n",
      "[28]   988 → where\n",
      "[29]  8524 → Jes\n",
      "[30]   546 → per\n",
      "[31]  4104 → Mad\n",
      "[32]  4881 → sen\n",
      "[33]   767 → man\n",
      "[34]  1179 → ages\n",
      "[35]   670 → his\n",
      "[36]  7601 → primary\n",
      "[37]  9124 → bank\n",
      "[38]   292 → ing\n",
      "[39] 14188 → activities\n",
      "[40] 29889 → .\n",
      "----------------------------------------\n",
      "Full decoded text: '<s> [INST] Which bank is Jesper Madsen currently using for his financial services? [/INST]Arctic Bank is the institution where Jesper Madsen manages his primary banking activities.'\n",
      "\n",
      "\n",
      "============================================================\n",
      "FULL TEXT TOKENIZED\n",
      "============================================================\n",
      "Total tokens: 63\n",
      "Token IDs: tensor([    1,   518, 25580, 29962,  1724,   526,   278,  7395,  6958,  4902,\n",
      "          393,  8524,   546,  4104,  4881, 15574,  3913,   363, 12084, 29973,\n",
      "          518, 29914, 25580, 29962, 29967, 27749,  4104,  4881,   508,   367,\n",
      "         6958,   287,  3025,  4876,   472,   432, 29889, 19581,  4881, 29947,\n",
      "        29947, 29992, 21980, 29889,   510,   322,   338,   884,  6136,   373,\n",
      "         5264,  5745,  1090,   278, 20147,  8952,   432, 29889, 19581,  4881,\n",
      "        29947, 29947, 29889])\n",
      "\n",
      "Token-to-String breakdown:\n",
      "----------------------------------------\n",
      "[ 0]     1 → <s>\n",
      "[ 1]   518 → [\n",
      "[ 2] 25580 → INST\n",
      "[ 3] 29962 → ]\n",
      "[ 4]  1724 → What\n",
      "[ 5]   526 → are\n",
      "[ 6]   278 → the\n",
      "[ 7]  7395 → online\n",
      "[ 8]  6958 → contact\n",
      "[ 9]  4902 → details\n",
      "[10]   393 → that\n",
      "[11]  8524 → Jes\n",
      "[12]   546 → per\n",
      "[13]  4104 → Mad\n",
      "[14]  4881 → sen\n",
      "[15] 15574 → commonly\n",
      "[16]  3913 → uses\n",
      "[17]   363 → for\n",
      "[18] 12084 → communication\n",
      "[19] 29973 → ?\n",
      "[20]   518 → [\n",
      "[21] 29914 → /\n",
      "[22] 25580 → INST\n",
      "[23] 29962 → ]\n",
      "[24] 29967 → J\n",
      "[25] 27749 → esper\n",
      "[26]  4104 → Mad\n",
      "[27]  4881 → sen\n",
      "[28]   508 → can\n",
      "[29]   367 → be\n",
      "[30]  6958 → contact\n",
      "[31]   287 → ed\n",
      "[32]  3025 → via\n",
      "[33]  4876 → email\n",
      "[34]   472 → at\n",
      "[35]   432 → j\n",
      "[36] 29889 → .\n",
      "[37] 19581 → mad\n",
      "[38]  4881 → sen\n",
      "[39] 29947 → 8\n",
      "[40] 29947 → 8\n",
      "[41] 29992 → @\n",
      "[42] 21980 → gmail\n",
      "[43] 29889 → .\n",
      "[44]   510 → com\n",
      "[45]   322 → and\n",
      "[46]   338 → is\n",
      "[47]   884 → also\n",
      "[48]  6136 → active\n",
      "[49]   373 → on\n",
      "[50]  5264 → social\n",
      "[51]  5745 → media\n",
      "[52]  1090 → under\n",
      "[53]   278 → the\n",
      "[54] 20147 → Twitter\n",
      "[55]  8952 → username\n",
      "[56]   432 → j\n",
      "[57] 29889 → .\n",
      "[58] 19581 → mad\n",
      "[59]  4881 → sen\n",
      "[60] 29947 → 8\n",
      "[61] 29947 → 8\n",
      "[62] 29889 → .\n",
      "----------------------------------------\n",
      "Full decoded text: '<s> [INST] What are the online contact details that Jesper Madsen commonly uses for communication? [/INST]Jesper Madsen can be contacted via email at j.madsen88@gmail.com and is also active on social media under the Twitter username j.madsen88.'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Usage for your three tokenized statements:\n",
    "print_tokens_readable(tokenizer, tokenized_subject1, \"Subject Tokenized\")\n",
    "print_tokens_readable(tokenizer, tokenized_subject2, \"Subject 2 Tokenized\")\n",
    "print_tokens_readable(tokenizer, full_text2_tokenized, \"Full Text 2 Tokenized\")\n",
    "print_tokens_readable(tokenizer, full_text_tokenized, \"Full Text Tokenized\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
